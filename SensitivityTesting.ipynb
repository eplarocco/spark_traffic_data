{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question:\n",
    "### What are the most influential variables on the severity of accidents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful Paper:\n",
    "    https://www.sciencedirect.com/science/article/pii/S2590198223000611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display Spark Output in scrollable format within jupyter notebook\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "import holidays\n",
    "from datetime import datetime, timezone\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, BinaryLogisticRegressionSummary\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/17 17:00:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Instantiate Spark Session\n",
    "spark = (SparkSession\n",
    "  .builder\n",
    "  .appName(\"US_Accidents\")\n",
    "  .getOrCreate())\n",
    "spark.sparkContext.setLogLevel(\"ERROR\") #supress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------+--------+----------+----------+-------------+-------+---------+----+----+-------------+--------------------------+--------------------+---------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+\n",
      "|Severity|Temperature|Humidity|Pressure|Visibility|Wind_Speed|Precipitation|Weekday|Rush_Hour|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate_Indicator|Sex_ratio|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|\n",
      "+--------+-----------+--------+--------+----------+----------+-------------+-------+---------+----+----+-------------+--------------------------+--------------------+---------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+\n",
      "|       2|         21|      85|      30|         1|        10|            0|      1|        1|   0|   1|(3,[0],[1.0])|                         0|                   0|     97.6|              8.0|              4.0|               13.1|    104583.0|        1.0|                   0|                   1|          0|\n",
      "|       2|         51|      29|      29|        10|         8|            0|      1|        0|   0|   0|(3,[0],[1.0])|                         1|                   0|     89.6|              7.7|              5.8|               12.7|    128378.0|      0.982|                   0|                   0|          0|\n",
      "|       3|         55|      83|      30|        10|         0|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   1|     94.6|              6.9|              5.4|               17.3|     52577.0|     0.9968|                   0|                   0|          0|\n",
      "|       2|         52|      94|      30|        10|         9|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|    106.8|              6.4|              8.2|               11.6|     48740.0|        1.0|                   0|                   0|          0|\n",
      "|       2|         25|      96|      30|         0|         0|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|     95.9|              5.6|              6.8|               14.4|     62956.0|     0.9887|                   0|                   0|          0|\n",
      "+--------+-----------+--------+--------+----------+----------+-------------+-------+---------+----+----+-------------+--------------------------+--------------------+---------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in Dataset\n",
    "df = spark.read.parquet(\"final_dataset_revised.parquet\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Rows count : 7026806\n",
      "DataFrame Columns count : 23\n"
     ]
    }
   ],
   "source": [
    "# Get row count\n",
    "rows = df.count()\n",
    "print(f\"DataFrame Rows count : {rows}\")\n",
    "\n",
    "# Get columns count\n",
    "cols = len(df.columns)\n",
    "print(f\"DataFrame Columns count : {cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------------------+\n",
      "|Severity|  count|           percent|\n",
      "+--------+-------+------------------+\n",
      "|       1|  65142|0.9270499285165977|\n",
      "|       3|1123799|15.993027272988611|\n",
      "|       4| 178821|2.5448404296347444|\n",
      "|       2|5659044| 80.53508236886005|\n",
      "+--------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Class Imbalance\n",
    "cts = df.groupBy(\"Severity\").count().withColumn('percent', (F.col('count') / rows)*100)\n",
    "cts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underperforming Tests Overview:\n",
    "\n",
    "## Tried Random split (80/20)\n",
    "- As predicted, model predicted severity = 2 for everything and they accuracy = the % of test samples with label = 2\n",
    "\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "## Undersampling (80/20) - undersampled each class by the smallest class for the training set - testing set everything else\n",
    "- This decreased the training set to about 3.5% of the original data set and the accuracy (~32% reflected that)\n",
    "- With undersampling, the performance might change with the sample taken\n",
    "\n",
    "sample = (cts.select(\"count\").rdd.min()[0])*0.8 #Undersample each class by 80% of the smallest class\n",
    "\n",
    "class1 = sample/(cts.select(\"count\").where(cts.Severity == '1').rdd.min()[0])\n",
    "\n",
    "class2 = sample/(cts.select(\"count\").where(cts.Severity == '2').rdd.min()[0])\n",
    "\n",
    "class3 = sample/(cts.select(\"count\").where(cts.Severity == '3').rdd.min()[0])\n",
    "\n",
    "class4 = sample/(cts.select(\"count\").where(cts.Severity == '4').rdd.min()[0])\n",
    "\n",
    "df.createOrReplaceTempView(\"data_view\") #Create a temporary view to use SQL\n",
    "\n",
    "fractions = {1: class1, 2: class2, 3: class3, 4: class4} #downsample each class to 80% of the smallest class\n",
    "\n",
    "train_data = df.sampleBy(\"Severity\", fractions, seed=42) #Use stratified sampling to maintain class distribution\n",
    "\n",
    "test_data = df.subtract(train_data)\n",
    "\n",
    "## Did not try full Oversampling\n",
    "- I'm always wary of oversampling amplyfying outliers especially with such high class imbalance and with regression trees that are already prone to overfitting\n",
    "## A combination of oversampling and undersampling may be a nice compramise\n",
    "- Did not check\n",
    "\n",
    "## Binary Classification (1|2 = 0, 3|4 = 1)\n",
    "- Best so far - model f1 score ~ 0.77 with base rf model - will obviously be better as half the options to guess from but still major improvement\n",
    "\n",
    "features = df.select([col for col in df.columns if col != \"Severity\" and col != \"Severity_Binary\"]).columns # Select all features except target variable\n",
    "\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features') # Vectorize Features\n",
    "\n",
    "model = RandomForestClassifier(featuresCol = 'features', labelCol = 'Severity_Binary') # Model\n",
    "  \n",
    "pipeline = Pipeline(stages=[assembler, model]) # Creating the pipeline \n",
    "\n",
    "fit_model = pipeline.fit(train_data) #train\n",
    "\n",
    "results = fit_model.transform(test_data) #predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+--------+----------+----------+-------------+-------+---------+----+----+-------------+--------------------------+--------------------+---------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+---------------+\n",
      "|Temperature|Humidity|Pressure|Visibility|Wind_Speed|Precipitation|Weekday|Rush_Hour|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate_Indicator|Sex_ratio|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|Severity_Binary|\n",
      "+-----------+--------+--------+----------+----------+-------------+-------+---------+----+----+-------------+--------------------------+--------------------+---------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+---------------+\n",
      "|         21|      85|      30|         1|        10|            0|      1|        1|   0|   1|(3,[0],[1.0])|                         0|                   0|     97.6|              8.0|              4.0|               13.1|    104583.0|        1.0|                   0|                   1|          0|              0|\n",
      "|         51|      29|      29|        10|         8|            0|      1|        0|   0|   0|(3,[0],[1.0])|                         1|                   0|     89.6|              7.7|              5.8|               12.7|    128378.0|      0.982|                   0|                   0|          0|              0|\n",
      "|         55|      83|      30|        10|         0|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   1|     94.6|              6.9|              5.4|               17.3|     52577.0|     0.9968|                   0|                   0|          0|              1|\n",
      "|         52|      94|      30|        10|         9|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|    106.8|              6.4|              8.2|               11.6|     48740.0|        1.0|                   0|                   0|          0|              0|\n",
      "|         25|      96|      30|         0|         0|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|     95.9|              5.6|              6.8|               14.4|     62956.0|     0.9887|                   0|                   0|          0|              0|\n",
      "+-----------+--------+--------+----------+----------+-------------+-------+---------+----+----+-------------+--------------------------+--------------------+---------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification (1 or 2 vs 3 or 4)\n",
    "df = df.withColumn('Severity_Binary', when((col(\"Severity\")==1) | (col(\"Severity\")==2), 0).otherwise(1))\n",
    "df = df.drop('Severity')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+------------------+\n",
      "|Severity_Binary|  count|           percent|\n",
      "+---------------+-------+------------------+\n",
      "|              1|1302620|18.537867702623352|\n",
      "|              0|5724186| 81.46213229737664|\n",
      "+---------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Class Imbalance\n",
    "cts = df.groupBy(\"Severity_Binary\").count().withColumn('percent', (F.col('count') / rows)*100)\n",
    "cts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Undersample each class by 80% of the smallest class\n",
    "sample = (cts.select(\"count\").rdd.min()[0])*0.8\n",
    "\n",
    "class0 = sample/(cts.select(\"count\").where(cts.Severity_Binary == '0').rdd.min()[0])\n",
    "class1 = sample/(cts.select(\"count\").where(cts.Severity_Binary == '1').rdd.min()[0])\n",
    "\n",
    "# Split Data by Class - Downsampling\n",
    "\n",
    "# Create a temporary view to use SQL\n",
    "df.createOrReplaceTempView(\"data_view\")\n",
    "\n",
    "# Calculate fractions for each class\n",
    "#fractions = df.groupBy(\"Severity\").count().rdd.map(lambda row: (row[0], 0.8)).collectAsMap() #samples 80% of each class\n",
    "fractions = {0: class0, 1: class1} #downsample each class to 80% of the smallest class\n",
    "\n",
    "# Use stratified sampling to maintain class distribution\n",
    "train_data = df.sampleBy(\"Severity_Binary\", fractions, seed=42)\n",
    "test_data = df.subtract(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.67241446540576\n",
      "+---------------+-------+------------------+\n",
      "|Severity_Binary|  count|           percent|\n",
      "+---------------+-------+------------------+\n",
      "|              1|1041638|49.958105977727826|\n",
      "|              0|1043385|50.041894022272174|\n",
      "+---------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Overall % Sampled from DF\n",
    "print(train_data.count()/df.count()*100)\n",
    "\n",
    "# Print % Sampled for each class within Train Data\n",
    "train_data.groupBy(\"Severity_Binary\").count().withColumn('percent', (F.col('count') / train_data.count())*100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.5318883145486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+-----------------+\n",
      "|Severity_Binary|  count|          percent|\n",
      "+---------------+-------+-----------------+\n",
      "|              1| 233834|6.102378746558451|\n",
      "|              0|3598016|93.89762125344156|\n",
      "+---------------+-------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print Overall % Sampled from DF\n",
    "print(test_data.count()/df.count()*100)\n",
    "\n",
    "# Print % Sampled for each class within Train Data\n",
    "test_data.groupBy(\"Severity_Binary\").count().withColumn('percent', (F.col('count') / test_data.count())*100).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Select all features except target variable\n",
    "feature_list = []\n",
    "for col in df.columns:\n",
    "    if col == 'Severity_Binary':\n",
    "        continue\n",
    "    else:\n",
    "        feature_list.append(col)\n",
    "\n",
    "features_list = ['Temperature(F)',\n",
    " 'Humidity(%)',\n",
    " 'Pressure(in)',\n",
    " 'Visibility(mi)',\n",
    " 'Wind_Speed(mph)',\n",
    " 'Precipitation(in)',\n",
    " 'Weekday',\n",
    " 'Rush Hour',\n",
    " #'Holiday',\n",
    " 'Rain',\n",
    " 'Snow',\n",
    " 'SeasonVec',\n",
    " 'SeasonVec2',\n",
    " 'SeasonVec3',\n",
    " 'Astronomical_TwilightIndex',\n",
    " 'Interstate Indicator',\n",
    " 'Sex ratio (males per 100 females)',\n",
    " 'Percent_Age_15-19',\n",
    " 'Percent_Age_20-24',\n",
    " 'Percent_Age_65_over',\n",
    " 'MedianIncome',\n",
    " 'Urban_Ratio',\n",
    " 'Traffic_Interference',\n",
    " 'Traffic_Intersection',\n",
    " 'Destination']       \n",
    "        \n",
    "# Vectorize Features\n",
    "assembler = VectorAssembler(inputCols=feature_list, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = assembler.transform(train_data)\n",
    "test_data = assembler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Temperature(F)', 'SeasonVec', -0.5175782168495072), ('SeasonVec', 'Temperature(F)', -0.5175782168495072), ('Percent_Age_15-19', 'Percent_Age_20-24', 0.46583032647265293), ('Percent_Age_20-24', 'Percent_Age_15-19', 0.46583032647265293), ('Percent_Age_20-24', 'Percent_Age_65_over', -0.40007330340669495), ('Percent_Age_65_over', 'Percent_Age_20-24', -0.40007330340669495)]\n"
     ]
    }
   ],
   "source": [
    "# Assemble features into a vector\n",
    "df_vector = assembler.transform(df)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = Correlation.corr(df_vector, \"features\").head()[0]\n",
    "\n",
    "# Turn into a dataframe\n",
    "corr_matrix_pd = pd.DataFrame(correlation_matrix.toArray(), columns=features_list, index=features_list)\n",
    "\n",
    "# Get the pairs of columns with correlation greater than 0.5\n",
    "high_corr_pairs = []\n",
    "for col1 in corr_matrix_pd.columns:\n",
    "    for col2 in corr_matrix_pd.columns:\n",
    "        if col1 != col2 and ((corr_matrix_pd[col1][col2] > 0.4) | (corr_matrix_pd[col1][col2] < -0.4)):\n",
    "            high_corr_pairs.append((col1, col2, corr_matrix_pd[col1][col2]))\n",
    "\n",
    "print(high_corr_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1328:=================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 0.46769075498002854, 0.8467884270366937, 0.8030794524837872)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Features Column\n",
    "train_data = assembler.transform(train_data)\n",
    "test_data = assembler.transform(test_data)\n",
    "\n",
    "# Define parameter ranges\n",
    "param_ranges = {\n",
    "    \"maxDepth\": [3,4],\n",
    "    \"maxIter\": [3,4]\n",
    "}\n",
    "\n",
    "# Create an evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity_Binary\", predictionCol=\"prediction\")\n",
    "\n",
    "# Perform sensitivity analysis\n",
    "results = []\n",
    "for maxDepth in param_ranges[\"maxDepth\"]:\n",
    "    for maxIter in param_ranges[\"maxIter\"]:\n",
    "        # Create a logistic regression model\n",
    "        gbt = GBTClassifier(labelCol=\"Severity_Binary\", featuresCol=\"features\", maxDepth=maxDepth, maxIter=maxIter)\n",
    "\n",
    "        # Fit the model\n",
    "        model = gbt.fit(train_data)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = model.transform(test_data)\n",
    "\n",
    "        # Evaluate the model\n",
    "        recall = evaluator.evaluate(predictions, {evaluator.metricName:\"truePositiveRateByLabel\", evaluator.metricLabel: 1.0})\n",
    "        f1 = evaluator.evaluate(predictions, {evaluator.metricName:\"f1\"})\n",
    "        accuracy = evaluator.evaluate(predictions, {evaluator.metricName:\"accuracy\"})\n",
    "\n",
    "        # Store the results\n",
    "        results.append((maxDepth, maxIter, recall, f1, accuracy))\n",
    "\n",
    "# Analyze the results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 761:============================================>            (7 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.6917945639834545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 17:12:45 ERROR Instrumentation: java.io.IOException: Path best_gbt_model already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n",
      "\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n",
      "\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n",
      "\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n",
      "\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o7026.save.\n: java.io.IOException: Path best_gbt_model already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Get and save the best model\u001b[39;00m\n\u001b[1;32m     33\u001b[0m bestModel \u001b[38;5;241m=\u001b[39m cvModel\u001b[38;5;241m.\u001b[39mbestModel\n\u001b[0;32m---> 34\u001b[0m \u001b[43mbestModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_gbt_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(bestModel\u001b[38;5;241m.\u001b[39mstages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m_java_obj\u001b[38;5;241m.\u001b[39mparamMap()) \n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(rcal)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyspark/ml/util.py:262\u001b[0m, in \u001b[0;36mMLWritable.save\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save this ML instance to the given path, a shortcut of 'write().save(path)'.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyspark/ml/util.py:213\u001b[0m, in \u001b[0;36mJavaMLWriter.save\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath should be a string, got type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(path))\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o7026.save.\n: java.io.IOException: Path best_gbt_model already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "# Create a RandomForestClassifier\n",
    "rf = GBTClassifier(labelCol=\"Severity_Binary\", featuresCol=\"features\")\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "# Define the parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxIter, [3, 6]) \\\n",
    "    .addGrid(rf.maxDepth, [3, 4]) \\\n",
    "    .build()\n",
    "\n",
    "# Create a CrossValidator\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"Severity_Binary\"\n",
    "                                                                      , predictionCol=\"prediction\"\n",
    "                                                                      , metricName=\"weightedRecall\"),\n",
    "                          numFolds=2,\n",
    "                          collectSubModels=True)\n",
    "\n",
    "# Fit the model\n",
    "cvModel = crossval.fit(train_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = cvModel.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "#evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity_Binary\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = evaluator.evaluate(predictions)\n",
    "print(\"Recall: \", recall)\n",
    "\n",
    "# Get and save the best model\n",
    "bestModel = cvModel.bestModel\n",
    "bestModel.save(\"best_gbt_model\")\n",
    "print(bestModel.stages[-1]._java_obj.paramMap()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Saved Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the saved best model\n",
    "loadedCvModel = PipelineModel.load(\"best_gbt_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Precision: 0.9158746279358325\n",
      "Weighted Recall: 0.6931749574325194\n",
      "Weighted F1 Score: 0.7730147581077779\n",
      "Accuracy: 0.6931749574325196\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 950:===============================>                         (5 + 4) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC: 0.6681312059814621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Further Metrics on Best Model\n",
    "pred = loadedCvModel.transform(test_data)\n",
    "\n",
    "#Evaluate (Confusion Matrix, Accuracy, Weighted Precision, Recall, and F1 Score)\n",
    "predictionAndLabels = pred.select(\"prediction\", \"Severity_Binary\")\n",
    "rdd = predictionAndLabels.rdd.map(lambda x: tuple(map(float, x)))\n",
    "multi_metrics = MulticlassMetrics(rdd)\n",
    "\n",
    "# Get precision, recall, and F1-score for each class\n",
    "print(f'Weighted Precision: {multi_metrics.weightedPrecision}') #would expect to be good when test sample has high majority 0 class\n",
    "print(f'Weighted Recall: {multi_metrics.weightedRecall}')\n",
    "print(f'Weighted F1 Score: {multi_metrics.weightedFMeasure()}') #would like to optimize this (balance of precision and recall)\n",
    "print(f'Accuracy: {multi_metrics.accuracy}') #could be skewed with imbalanced test set\n",
    "\n",
    "# Plot confusion matrix\n",
    "cf = multi_metrics.confusionMatrix().toArray()\n",
    "cf_df = pd.DataFrame(cf, columns=['0', '1'])\n",
    "sns.heatmap(cf_df, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()\n",
    "\n",
    "# AUC Score\n",
    "binary_metrics = BinaryClassificationMetrics(rdd)\n",
    "auc = binary_metrics.areaUnderROC\n",
    "print(\"Area Under ROC:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent_Age_15-19: 0.6538633098522804\n",
      "Wind_Speed(mph): 0.11309523586636983\n",
      "Pressure(in): 0.021411067760803683\n",
      "Urban_Ratio: 0.020182736604989756\n",
      "Traffic_Intersection: 0.01307051332883975\n",
      "Sex ratio (males per 100 females): 0.006172481797186255\n",
      "Temperature(F): 0.00493695556091131\n",
      "Traffic_Interference: 0.004705629286118825\n",
      "Visibility(mi): 0.0035782185663899894\n",
      "Destination: 0.0030973008775653\n",
      "Weekday: 0.0026137961573831966\n",
      "Percent_Age_65_over: 0.0024557402387279104\n",
      "Snow: 0.0020169011529076507\n",
      "MedianIncome: 0.0013424964805030298\n",
      "Percent_Age_20-24: 0.0008952325602054058\n",
      "Humidity(%): 0.00013728881673452133\n",
      "Rush Hour: 3.356935485804044e-05\n",
      "Precipitation(in): 0.0\n",
      "Holiday: 0.0\n",
      "Rain: 0.0\n",
      "SeasonVec: 0.0\n",
      "Astronomical_TwilightIndex: 0.0\n",
      "Interstate Indicator: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_importances = cvModel.bestModel.stages[-1].featureImportances\n",
    "\n",
    "# Create a mapping between feature names and their importance scores\n",
    "feature_importance_dict = {}\n",
    "feature_names = assembler.getInputCols()\n",
    "for i, feature_name in enumerate(feature_names):\n",
    "    feature_importance_dict[feature_name] = feature_importances[i]\n",
    "\n",
    "# Sort the feature importance dictionary by score in descending order\n",
    "sorted_feature_importances = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the feature importances\n",
    "for feature_name, importance_score in sorted_feature_importances:\n",
    "    print(f\"{feature_name}: {importance_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions/Wierd Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why is my undersampling code not using all available data?\n",
    "\n",
    "#Can't figure out ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "Temperature(F): 0.0009213015483506297\n",
      "Humidity(%): 0.002540609439652656\n",
      "Pressure(in): 0.020450333607135187\n",
      "Visibility(mi): 0.0013161062441105088\n",
      "Wind_Speed(mph): 0.0940699616214557\n",
      "Precipitation(in): 0.0\n",
      "Weekday: 0.0005017290970311592\n",
      "Rush Hour: 0.0\n",
      "Holiday: 0.0\n",
      "Rain: 0.0023240584289040468\n",
      "Snow: 0.0\n",
      "SeasonVec: 0.0\n",
      "Astronomical_TwilightIndex: 0.0\n",
      "Interstate Indicator: 0.0\n",
      "Sex ratio (males per 100 females): 0.0\n",
      "Percent_Age_15-19: 0.7070260166982979\n",
      "Percent_Age_20-24: 0.0002243347183741944\n",
      "Percent_Age_65_over: 0.0\n",
      "MedianIncome: 0.003956996597709727\n",
      "Urban_Ratio: 0.0\n",
      "Traffic_Interference: 0.01904514582410056\n",
      "Traffic_Intersection: 0.0169767010785899\n",
      "Destination: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Feature Importances\n",
    "bestModel = cvModel.bestModel.stages[-1]  # Assuming the last stage in the pipeline is the model\n",
    "\n",
    "featureImportances = bestModel.featureImportances\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(test_data.columns[:-1], featureImportances):\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(25, {0: 0.0009, 1: 0.0025, 2: 0.0205, 3: 0.0013, 4: 0.0941, 6: 0.0005, 9: 0.0023, 15: 0.707, 16: 0.0002, 18: 0.004, 20: 0.019, 21: 0.017, 23: 0.1054, 24: 0.0253})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.featureImportances #why are there 25? when only 23 features? Onehotencoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
