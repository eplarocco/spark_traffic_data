{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5853abf8-e203-4758-aa36-44a0799eb090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "import holidays\n",
    "from datetime import datetime, timezone\n",
    "from pyspark.ml.classification import RandomForestClassifier, BinaryLogisticRegressionSummary\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\n",
    "from pyspark.ml.pipeline import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aeec964-9667-4a66-98af-f7c55a9c3b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/11 13:01:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Spark Session\n",
    "spark = (SparkSession\n",
    "  .builder\n",
    "  .appName(\"US_Accidents\")\n",
    "  .getOrCreate())\n",
    "spark.sparkContext.setLogLevel(\"ERROR\") #supress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa238c88-9dbf-4c03-949b-77dc62fb3ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+\n",
      "|Severity|Temperature(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Speed(mph)|Precipitation(in)|Weekday|Rush Hour|Holiday|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate Indicator|Sex ratio (males per 100 females)|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|MedianIncome_MarginOfError|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+\n",
      "|       2|            21|         85|          30|             1|             10|                0|      1|        1|      0|   0|   1|(3,[0],[0.0])|                         0|                   0|                             97.6|              8.0|              4.0|               13.1|    104583.0|                    6161.0|        1.0|                   0|                   1|          0|\n",
      "|       2|            51|         29|          29|            10|              8|                0|      1|        0|      0|   0|   0|(3,[0],[0.0])|                         1|                   0|                             89.6|              7.7|              5.8|               12.7|    128378.0|                    7418.0|      0.982|                   0|                   0|          0|\n",
      "|       3|            55|         83|          30|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   1|                             94.6|              6.9|              5.4|               17.3|     52577.0|                    2897.0|     0.9968|                   0|                   0|          0|\n",
      "|       2|            52|         94|          30|            10|              9|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            106.8|              6.4|              8.2|               11.6|     48740.0|                    3484.0|        1.0|                   0|                   0|          0|\n",
      "|       2|            25|         96|          30|             0|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             95.9|              5.6|              6.8|               14.4|     62956.0|                    2229.0|     0.9887|                   0|                   0|          0|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in Data\n",
    "df = spark.read.parquet(\"final_dataset.parquet\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f2adb9e-01e0-4ec7-9fd6-7f8a05d1d0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels in Severity: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Confirm that there are 4 Classes\n",
    "unique_labels = df.select(\"Severity\").distinct().count()\n",
    "print(f\"Number of unique labels in Severity: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcda1183-0b9a-49a7-85d3-3f595aa87a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create list of features\n",
    "feature_list = []\n",
    "for col in df.columns:\n",
    "    if col == 'Severity':\n",
    "        continue\n",
    "    elif col == 'SeasonVec':\n",
    "        continue\n",
    "    else:\n",
    "        feature_list.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4c2599-9c86-4679-a4a1-50d93661c602",
   "metadata": {},
   "source": [
    "# Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c4ad6c-409d-4472-b1f7-8325ac3ec1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assemble data for logistic regression model\n",
    "assembler = VectorAssembler(inputCols=feature_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba99c30-6557-4c4f-88a5-7696e4f9c90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels in Severity: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Confirm that there are 4 Classes after assembling\n",
    "unique_labels = df.select(\"Severity\").distinct().count()\n",
    "print(f\"Number of unique labels in Severity: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a4b7db-ed5e-428b-809b-bccdc5fb8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "splits = df.randomSplit([0.8, 0.2], 314)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd8be75-6c5c-4bdc-a9f3-583cf9e2aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Standardize the predictors\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(train)\n",
    "scaledTrainData = scalerModel.transform(train)\n",
    "scaledTestData = scalerModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba3f6737-b687-4447-ac1d-f13d80912d30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected number of classes: 5\n",
      "Coefficients: 5 X 23 CSRMatrix\n",
      "\n",
      "Intercept: [-10.352852767967923,0.5063385243198986,4.972389653205689,3.3563424695647748,1.51778212087756]\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression model with intercept\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "lr = LogisticRegression(labelCol='Severity',\n",
    "                        featuresCol='scaledFeatures',\n",
    "                        maxIter=10, \n",
    "                        regParam=0.3, \n",
    "                        elasticNetParam=0.8,\n",
    "                        family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(scaledTrainData)\n",
    "print(f\"Detected number of classes: {lrModel.numClasses}\")\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5a16f62-c7b3-44b3-ad4e-43a038aadff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2', '3', '4', '1']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you used StringIndexer for encoding the 'Severity' column\n",
    "indexer = StringIndexer(inputCol=\"Severity\", outputCol=\"SeverityIndex\")\n",
    "indexer_model = indexer.fit(scaledTrainData)\n",
    "indexer_model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bb0ef16-3fe8-4d07-9bca-00659de40f12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       2.0|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.805556522845291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# compute predictions. this will append column \"prediction\" to dataframe\n",
    "lrPred = lrModel.transform(scaledTestData)\n",
    "lrPred.select(\"prediction\").distinct().show()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Severity', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(lrPred, {evaluator.metricName: \"accuracy\"})\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c73396e-66ff-4a34-ade8-ba6540d7f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6489213114985959\n",
      "Recall: 0.805556522845291\n",
      "F1 Score: 0.7188047599595404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "precision = evaluator.evaluate(lrPred, {evaluator.metricName: 'weightedPrecision'})\n",
    "recall = evaluator.evaluate(lrPred, {evaluator.metricName: 'weightedRecall'})\n",
    "f1_score = evaluator.evaluate(lrPred, {evaluator.metricName: 'f1'})\n",
    "#recallByLabel = evaluator.evaluate(lrPred, {evaluator.metricName: 'recallByLabel'})\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1_score}')\n",
    "#print(f'Recall by Label: {recallByLabel}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1736f0d-ea5d-42a9-a8b3-57248d1166f5",
   "metadata": {},
   "source": [
    "# Always predicts majority class (class 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98b4a317-9b06-4da6-ab72-f1353193205d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|Severity|accuracy|\n",
      "+--------+--------+\n",
      "|       1|     0.0|\n",
      "|       3|     0.0|\n",
      "|       4|     0.0|\n",
      "|       2|     1.0|\n",
      "+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Add a column to indicate correct or incorrect predictions\n",
    "predictions = lrPred.withColumn(\n",
    "    'is_correct', F.expr(\"CASE WHEN Severity = prediction THEN 1 ELSE 0 END\")\n",
    ")\n",
    "\n",
    "# Calculate accuracy by class\n",
    "accuracy_by_class = predictions.groupBy('Severity').agg(\n",
    "    (F.sum('is_correct') / F.count('Severity')).alias('accuracy')\n",
    ")\n",
    "\n",
    "# Show per-class accuracy\n",
    "accuracy_by_class.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5320e4-0ade-479e-bb76-4b327ea693d0",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d673248-9337-4a72-9957-1bfa4cb7a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "df = spark.read.parquet(\"final_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9e9549b-e3d5-4210-a5be-6f6acc7e2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebdc8e96-3be3-4c58-8ceb-7a00335d18bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+--------------------+\n",
      "|Severity|Temperature(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Speed(mph)|Precipitation(in)|Weekday|Rush Hour|Holiday|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate Indicator|Sex ratio (males per 100 females)|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|MedianIncome_MarginOfError|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|            features|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+--------------------+\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            36|         86|          30|             7|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             90.3|             10.4|              8.3|               20.3|     69934.0|                   34117.0|     0.5088|                   0|                   1|          0|(23,[0,1,2,3,6,7,...|\n",
      "|       1|            27|         75|          29|             7|              5|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            109.5|              4.2|              8.0|               12.1|     65327.0|                   12109.0|     0.9993|                   0|                   0|          0|(23,[0,1,2,3,4,6,...|\n",
      "|       1|            39|         67|          30|            10|              6|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             96.4|              9.4|              7.6|               14.8|     76198.0|                    5620.0|        1.0|                   0|                   0|          0|(23,[0,1,2,3,4,6,...|\n",
      "|       1|            31|         82|          30|            10|              5|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             95.3|              6.2|              9.9|               13.6|     47059.0|                    3091.0|     0.9894|                   0|                   0|          0|(23,[0,1,2,3,4,6,...|\n",
      "|       1|            34|         79|          30|            10|              6|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             92.7|              5.6|              5.6|               14.7|     74060.0|                    3331.0|     0.9996|                   0|                   0|          0|(23,[0,1,2,3,4,6,...|\n",
      "|       1|            19|         61|          30|            10|              6|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             88.8|              7.0|              6.1|               12.8|    111792.0|                    4997.0|     0.9163|                   0|                   0|          0|(23,[0,1,2,3,4,6,...|\n",
      "|       1|             9|         61|          30|            10|              6|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            103.9|              4.0|              7.1|               14.6|     48055.0|                    2599.0|        1.0|                   0|                   1|          1|[9.0,61.0,30.0,10...|\n",
      "|       1|            30|         93|          29|            10|              9|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   1|                            112.9|              6.0|              4.7|               10.5|     53740.0|                    4526.0|     0.9844|                   0|                   0|          0|[30.0,93.0,29.0,1...|\n",
      "|       1|            36|         64|          29|            10|              3|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             83.6|              6.7|              3.3|               21.1|     46506.0|                    5617.0|      0.035|                   0|                   0|          0|(23,[0,1,2,3,4,6,...|\n",
      "|       1|            28|         93|          29|             6|              5|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            101.3|              5.0|              4.6|               14.8|     56875.0|                    5458.0|     0.5299|                   0|                   0|          0|(23,[0,1,2,3,4,6,...|\n",
      "|       1|            44|         51|          28|            10|              3|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             92.3|              4.3|              5.2|               22.6|     86746.0|                    3661.0|        1.0|                   0|                   0|          0|(23,[0,1,2,3,4,6,...|\n",
      "|       1|            32|         87|          29|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             97.9|              6.0|              4.9|               15.8|     77148.0|                    2664.0|        1.0|                   0|                   0|          0|(23,[0,1,2,3,6,7,...|\n",
      "|       1|            28|         66|          25|            10|             20|                0|      1|        0|      0|   0|   0|(3,[0],[0.0])|                         1|                   0|                            106.5|              7.5|              5.9|               10.4|    101038.0|                    6756.0|     0.9946|                   0|                   1|          0|[28.0,66.0,25.0,1...|\n",
      "|       1|            57|         83|          30|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   1|                             89.4|              7.0|              5.1|               21.5|     79759.0|                    7118.0|        1.0|                   0|                   0|          0|(23,[0,1,2,3,6,7,...|\n",
      "|       1|            58|         27|          29|            10|             13|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   1|                            111.3|              7.6|              7.7|                7.0|     38121.0|                    2311.0|        1.0|                   0|                   0|          0|[58.0,27.0,29.0,1...|\n",
      "|       1|            50|        100|          27|            10|              5|                0|      1|        1|      1|   0|   0|(3,[0],[0.0])|                         0|                   0|                             91.8|              4.5|              6.7|               26.5|     56649.0|                    2853.0|     0.9949|                   0|                   0|          0|[50.0,100.0,27.0,...|\n",
      "|       1|            48|         93|          29|            10|              5|                0|      1|        0|      0|   0|   0|(3,[0],[0.0])|                         1|                   0|                            111.3|              7.6|              7.7|                7.0|     38121.0|                    2311.0|        1.0|                   0|                   1|          0|[48.0,93.0,29.0,1...|\n",
      "|       1|            32|         64|          26|            10|             16|                0|      1|        0|      1|   0|   0|(3,[0],[0.0])|                         1|                   0|                            112.0|              0.0|             15.4|               15.9|     30000.0|                    7106.0|        0.0|                   0|                   0|          0|(23,[0,1,2,3,4,6,...|\n",
      "|       1|            26|        100|          25|             1|             16|                0|      1|        0|      0|   0|   1|(3,[0],[0.0])|                         1|                   1|                             96.9|              5.4|              7.5|               12.8|     68299.0|                    4673.0|        1.0|                   0|                   0|          0|[26.0,100.0,25.0,...|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:===========================================>              (6 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Severity|count|\n",
      "+--------+-----+\n",
      "|       1|65142|\n",
      "|       3|65399|\n",
      "|       4|65355|\n",
      "|       2|64717|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Step 1: Group by 'Severity' and count occurrences\n",
    "class_counts = df.groupBy(\"Severity\").count()\n",
    "\n",
    "# Step 2: Use PySpark's min() function to find the minimum count\n",
    "min_class_size = class_counts.agg(F.min('count')).collect()[0][0]\n",
    "\n",
    "undersampled_df_list = []\n",
    "\n",
    "for row in class_counts.collect():\n",
    "    class_label = row['Severity']\n",
    "    class_size = row['count']\n",
    "\n",
    "    if class_size > min_class_size:\n",
    "        # Sample the data for this class to the size of the minimum class\n",
    "        class_data = df.filter(F.col(\"Severity\") == class_label)\n",
    "        class_data_undersampled = class_data.sample(withReplacement=False, fraction=min_class_size / class_size)\n",
    "    else:\n",
    "        # For classes that are already at the minimum size, keep all samples\n",
    "        class_data_undersampled = df.filter(F.col(\"Severity\") == class_label)\n",
    "\n",
    "    undersampled_df_list.append(class_data_undersampled)\n",
    "\n",
    "# Combine all the undersampled DataFrames\n",
    "undersampled_df = undersampled_df_list[0]  # start with the first one\n",
    "for df in undersampled_df_list[1:]:\n",
    "    undersampled_df = undersampled_df.union(df)\n",
    "\n",
    "# Show the result\n",
    "undersampled_df.show()\n",
    "\n",
    "# Step 4: Group by 'Severity' and count the occurrences in the undersampled DataFrame\n",
    "undersampled_class_counts = undersampled_df.groupBy(\"Severity\").count()\n",
    "\n",
    "# Show the result\n",
    "undersampled_class_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68d77b26-7702-4b67-91b6-355cf8a8f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "splits = undersampled_df.randomSplit([0.8, 0.2], 314)\n",
    "undersampled_train = splits[0]\n",
    "undersampled_test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8606355a-82e9-43cc-b841-b406bd57b4da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Severity|count|\n",
      "+--------+-----+\n",
      "|       1|52009|\n",
      "|       3|52184|\n",
      "|       4|52291|\n",
      "|       2|51736|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Group by 'Severity' and count the occurrences in the training undersampled DataFrame\n",
    "undersampled_class_counts = undersampled_train.groupBy(\"Severity\").count()\n",
    "\n",
    "# Show the result\n",
    "undersampled_class_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c185c0ed-b840-47c4-a1e5-b83a1a86e12b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Severity|count|\n",
      "+--------+-----+\n",
      "|       1|13133|\n",
      "|       3|13215|\n",
      "|       4|13064|\n",
      "|       2|12981|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Group by 'Severity' and count the occurrences in the testing undersampled DataFrame\n",
    "undersampled_class_counts = undersampled_test.groupBy(\"Severity\").count()\n",
    "\n",
    "# Show the result\n",
    "undersampled_class_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83b0bd6f-81e5-49cc-aa9e-05458fb3565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Standardize the predictors\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "undersampled_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "undersampled_scalerModel = undersampled_scaler.fit(undersampled_train)\n",
    "undersampled_scaledTrainData = undersampled_scalerModel.transform(undersampled_train)\n",
    "undersampled_scaledTestData = undersampled_scalerModel.transform(undersampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4d4cafa-c999-4350-bf0d-b223c62303fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected number of classes: 5\n",
      "Coefficients: 5 X 23 CSRMatrix\n",
      "\n",
      "Intercept: [-8.718887089228927,2.1789981477907783,2.1735858168777313,2.1820987362526707,2.1842043883077458]\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression model with intercept\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "undersampled_lr = LogisticRegression(labelCol='Severity',\n",
    "                        featuresCol='scaledFeatures',\n",
    "                        maxIter=10, \n",
    "                        regParam=0.3, \n",
    "                        elasticNetParam=0.8,\n",
    "                        family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "undersampled_lrModel = undersampled_lr.fit(undersampled_scaledTrainData)\n",
    "print(f\"Detected number of classes: {undersampled_lrModel.numClasses}\")\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(undersampled_lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(undersampled_lrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8964f9a3-ea5f-4628-8364-7ae4f9296815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4', '3', '1', '2']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you used StringIndexer for encoding the 'Severity' column\n",
    "indexer = StringIndexer(inputCol=\"Severity\", outputCol=\"SeverityIndex\")\n",
    "indexer_model = indexer.fit(undersampled_scaledTrainData)\n",
    "indexer_model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "980ebfd1-693d-41cb-a032-7cdf2f26cb3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       4.0|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 266:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2493462867176913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# compute predictions. this will append column \"prediction\" to dataframe\n",
    "undersampled_lrPred = undersampled_lrModel.transform(undersampled_scaledTestData)\n",
    "undersampled_lrPred.select(\"prediction\").distinct().show()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Severity', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(undersampled_lrPred, {evaluator.metricName: \"accuracy\"})\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "687b0109-121a-4c63-8c6a-b2ca5257d7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 272:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.062173570699901114\n",
      "Recall: 0.2493462867176913\n",
      "F1 Score: 0.0995297642629488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "precision = evaluator.evaluate(undersampled_lrPred, {evaluator.metricName: 'weightedPrecision'})\n",
    "recall = evaluator.evaluate(undersampled_lrPred, {evaluator.metricName: 'weightedRecall'})\n",
    "f1_score = evaluator.evaluate(undersampled_lrPred, {evaluator.metricName: 'f1'})\n",
    "#recallByLabel = evaluator.evaluate(undersampled_lrPred, {evaluator.metricName: 'recallByLabel'})\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1_score}')\n",
    "#print(f'Recall by Label: {recallByLabel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53e4bc8a-438b-4297-b36e-796b188423e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 274:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|Severity|accuracy|\n",
      "+--------+--------+\n",
      "|       1|     0.0|\n",
      "|       3|     0.0|\n",
      "|       4|     1.0|\n",
      "|       2|     0.0|\n",
      "+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Add a column to indicate correct or incorrect predictions\n",
    "predictions = undersampled_lrPred.withColumn(\n",
    "    'is_correct', F.expr(\"CASE WHEN Severity = prediction THEN 1 ELSE 0 END\")\n",
    ")\n",
    "\n",
    "# Calculate accuracy by class\n",
    "accuracy_by_class = predictions.groupBy('Severity').agg(\n",
    "    (F.sum('is_correct') / F.count('Severity')).alias('accuracy')\n",
    ")\n",
    "\n",
    "# Show per-class accuracy\n",
    "accuracy_by_class.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d5369bb-bec9-4d2a-9e80-97ccbb5ef71b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline F1 score: 0.0995297642629488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 323:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances (by drop in F1 score):\n",
      "Temperature(F): 0.0\n",
      "Humidity(%): 0.0\n",
      "Pressure(in): 0.0\n",
      "Visibility(mi): 0.0\n",
      "Wind_Speed(mph): 0.0\n",
      "Precipitation(in): 0.0\n",
      "Weekday: 0.0\n",
      "Rush Hour: 0.0\n",
      "Holiday: 0.0\n",
      "Rain: 0.0\n",
      "Snow: 0.0\n",
      "Astronomical_TwilightIndex: 0.0\n",
      "Interstate Indicator: 0.0\n",
      "Sex ratio (males per 100 females): 0.0\n",
      "Percent_Age_15-19: 0.0\n",
      "Percent_Age_20-24: 0.0\n",
      "Percent_Age_65_over: 0.0\n",
      "MedianIncome: 0.0\n",
      "MedianIncome_MarginOfError: 0.0\n",
      "Urban_Ratio: 0.0\n",
      "Traffic_Interference: 0.0\n",
      "Traffic_Intersection: 0.0\n",
      "Destination: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, data, evaluator):\n",
    "    predictions = model.transform(data)\n",
    "    return evaluator.evaluate(predictions)\n",
    "\n",
    "# Initialize the evaluator (using F1 score here)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Calculate baseline performance on test data\n",
    "baseline_score = evaluate_model(undersampled_lrModel, undersampled_scaledTestData, evaluator)\n",
    "print(f\"Baseline F1 score: {baseline_score}\")\n",
    "\n",
    "# Assuming you know which features were used in the VectorAssembler, replace these with the actual feature names\n",
    "feature_names = feature_list  # Replace with actual feature names from your dataset\n",
    "\n",
    "# Initialize a dictionary to store feature importances\n",
    "feature_importances = {}\n",
    "\n",
    "# Loop through each feature and calculate permutation importance\n",
    "for feature in feature_names:\n",
    "    # Shuffle the feature column\n",
    "    shuffled_data = undersampled_scaledTestData.withColumn(feature, F.rand())  # Shuffle values in the column\n",
    "    \n",
    "    # Evaluate the model with the shuffled feature\n",
    "    score_with_permuted_feature = evaluate_model(undersampled_lrModel, shuffled_data, evaluator)\n",
    "    \n",
    "    # Calculate the drop in performance\n",
    "    importance = baseline_score - score_with_permuted_feature\n",
    "    feature_importances[feature] = importance\n",
    "\n",
    "# Sort the features by importance (i.e., the drop in F1 score)\n",
    "sorted_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Feature Importances (by drop in F1 score):\")\n",
    "for feature, importance in sorted_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30352475-47d6-4c53-b9d2-d4540f86ec65",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d64d8284-b16e-4cbc-8752-0d6275b2cc88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "df = spark.read.parquet(\"final_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6ac702a-c542-4b49-9c27-b780194cf3d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "115cabdf-b16b-4ad1-a5c2-18e8e6cdaf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+--------------------+\n",
      "|Severity|Temperature(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Speed(mph)|Precipitation(in)|Weekday|Rush Hour|Holiday|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate Indicator|Sex ratio (males per 100 females)|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|MedianIncome_MarginOfError|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|            features|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+--------------------+\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "|       1|            26|         75|          25|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            107.8|              8.2|             14.2|               10.4|     39822.0|                    3367.0|     0.9986|                   0|                   1|          1|[26.0,75.0,25.0,1...|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 336:===================================>                     (5 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|Severity|  count|\n",
      "+--------+-------+\n",
      "|       1|5659217|\n",
      "|       3|5656247|\n",
      "|       4|5659448|\n",
      "|       2|5659044|\n",
      "+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Step 1: Group by 'Severity' and count occurrences\n",
    "class_counts = df.groupBy(\"Severity\").count()\n",
    "\n",
    "# Step 2: Use PySpark's max() function to find the maximum count\n",
    "max_class_size = class_counts.agg(F.max('count')).collect()[0][0]\n",
    "\n",
    "# Initialize a list to store the oversampled DataFrames for each class\n",
    "oversampled_df_list = []\n",
    "\n",
    "# Step 3: Oversample each class to match the maximum class size\n",
    "for row in class_counts.collect():\n",
    "    class_label = row['Severity']\n",
    "    class_size = row['count']\n",
    "\n",
    "    # Filter data for the current class\n",
    "    class_data = df.filter(F.col(\"Severity\") == class_label)\n",
    "\n",
    "    if class_size < max_class_size:\n",
    "        # Oversample the class to match the maximum class size\n",
    "        class_data_oversampled = class_data.sample(withReplacement=True, fraction=max_class_size / class_size)\n",
    "    else:\n",
    "        # Retain the original data for the class if it's already at the maximum size\n",
    "        class_data_oversampled = class_data\n",
    "\n",
    "    # Add the oversampled data to the list\n",
    "    oversampled_df_list.append(class_data_oversampled)\n",
    "\n",
    "# Step 4: Combine all the oversampled DataFrames\n",
    "oversampled_df = oversampled_df_list[0]  # start with the first one\n",
    "for class_df in oversampled_df_list[1:]:\n",
    "    oversampled_df = oversampled_df.union(class_df)\n",
    "\n",
    "# Show the result of oversampling\n",
    "oversampled_df.show()\n",
    "\n",
    "# Step 5: Group by 'Severity' and count the occurrences in the oversampled DataFrame\n",
    "oversampled_class_counts = oversampled_df.groupBy(\"Severity\").count()\n",
    "\n",
    "# Show the result\n",
    "oversampled_class_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "192f497b-5c20-4401-ac90-3c212f315c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "splits = oversampled_df.randomSplit([0.8, 0.2], 314)\n",
    "oversampled_train = splits[0]\n",
    "oversampled_test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e908e326-bba3-41f5-8ea9-774a7f07b6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 339:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|Severity|  count|\n",
      "+--------+-------+\n",
      "|       1|4525580|\n",
      "|       3|4524452|\n",
      "|       4|4526837|\n",
      "|       2|4526438|\n",
      "+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Group by 'Severity' and count the occurrences in the training oversampled DataFrame\n",
    "oversampled_class_counts = oversampled_train.groupBy(\"Severity\").count()\n",
    "\n",
    "# Show the result\n",
    "oversampled_class_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "743a8256-e994-43c2-b1ed-6d08c48276d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 342:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|Severity|  count|\n",
      "+--------+-------+\n",
      "|       1|1133637|\n",
      "|       3|1131795|\n",
      "|       4|1132611|\n",
      "|       2|1132606|\n",
      "+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Group by 'Severity' and count the occurrences in the testing oversampled DataFrame\n",
    "oversampled_class_counts = oversampled_test.groupBy(\"Severity\").count()\n",
    "\n",
    "# Show the result\n",
    "oversampled_class_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1094033f-a492-417b-b2cd-3d1053a2c5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Standardize the predictors\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "oversampled_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "oversampled_scalerModel = oversampled_scaler.fit(oversampled_train)\n",
    "oversampled_scaledTrainData = oversampled_scalerModel.transform(oversampled_train)\n",
    "oversampled_scaledTestData = oversampled_scalerModel.transform(oversampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11ab68e0-bee3-47b6-a537-238dd28f8f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected number of classes: 5\n",
      "Coefficients: 5 X 23 CSRMatrix\n",
      "\n",
      "Intercept: [-12.260248820919148,3.0650077037447794,3.0651972746919434,3.064758422912057,3.065285419570369]\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression model with intercept\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "oversampled_lr = LogisticRegression(labelCol='Severity',\n",
    "                        featuresCol='scaledFeatures',\n",
    "                        maxIter=10, \n",
    "                        regParam=0.3, \n",
    "                        elasticNetParam=0.8,\n",
    "                        family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "oversampled_lrModel = oversampled_lr.fit(oversampled_scaledTrainData)\n",
    "print(f\"Detected number of classes: {oversampled_lrModel.numClasses}\")\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(oversampled_lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(oversampled_lrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "650a94d9-cea8-4b80-8dad-0753475b60ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4', '2', '1', '3']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you used StringIndexer for encoding the 'Severity' column\n",
    "indexer = StringIndexer(inputCol=\"Severity\", outputCol=\"SeverityIndex\")\n",
    "indexer_model = indexer.fit(oversampled_scaledTrainData)\n",
    "indexer_model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f958bb9-3b64-454a-ac30-c69c220798c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       4.0|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 358:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2499886881548317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# compute predictions. this will append column \"prediction\" to dataframe\n",
    "oversampled_lrPred = oversampled_lrModel.transform(oversampled_scaledTestData)\n",
    "oversampled_lrPred.select(\"prediction\").distinct().show()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Severity', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(oversampled_lrPred, {evaluator.metricName: \"accuracy\"})\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff68f8ec-7205-480d-be4b-d08b15c3781e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 364:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.062494344205373684\n",
      "Recall: 0.2499886881548317\n",
      "F1 Score: 0.09999185560250883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "precision = evaluator.evaluate(oversampled_lrPred, {evaluator.metricName: 'weightedPrecision'})\n",
    "recall = evaluator.evaluate(oversampled_lrPred, {evaluator.metricName: 'weightedRecall'})\n",
    "f1_score = evaluator.evaluate(oversampled_lrPred, {evaluator.metricName: 'f1'})\n",
    "#recallByLabel = evaluator.evaluate(oversampled_lrPred, {evaluator.metricName: 'recallByLabel'})\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1_score}')\n",
    "#print(f'Recall by Label: {recallByLabel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa891995-9bd3-429f-9bc7-5f7dfc8f7ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 366:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|Severity|accuracy|\n",
      "+--------+--------+\n",
      "|       1|     0.0|\n",
      "|       3|     0.0|\n",
      "|       4|     1.0|\n",
      "|       2|     0.0|\n",
      "+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Add a column to indicate correct or incorrect predictions\n",
    "predictions = oversampled_lrPred.withColumn(\n",
    "    'is_correct', F.expr(\"CASE WHEN Severity = prediction THEN 1 ELSE 0 END\")\n",
    ")\n",
    "\n",
    "# Calculate accuracy by class\n",
    "accuracy_by_class = predictions.groupBy('Severity').agg(\n",
    "    (F.sum('is_correct') / F.count('Severity')).alias('accuracy')\n",
    ")\n",
    "\n",
    "# Show per-class accuracy\n",
    "accuracy_by_class.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611ed9a-694c-4c49-aaad-d60008d34b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline F1 score: 0.09999185560250883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 415:=====================>                                   (3 + 1) / 8]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, data, evaluator):\n",
    "    predictions = model.transform(data)\n",
    "    return evaluator.evaluate(predictions)\n",
    "\n",
    "# Initialize the evaluator (using F1 score here)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Calculate baseline performance on test data\n",
    "baseline_score = evaluate_model(oversampled_lrModel, oversampled_scaledTestData, evaluator)\n",
    "print(f\"Baseline F1 score: {baseline_score}\")\n",
    "\n",
    "# Assuming you know which features were used in the VectorAssembler, replace these with the actual feature names\n",
    "feature_names = feature_list  # Replace with actual feature names from your dataset\n",
    "\n",
    "# Initialize a dictionary to store feature importances\n",
    "feature_importances = {}\n",
    "\n",
    "# Loop through each feature and calculate permutation importance\n",
    "for feature in feature_names:\n",
    "    # Shuffle the feature column\n",
    "    shuffled_data = oversampled_scaledTestData.withColumn(feature, F.rand())  # Shuffle values in the column\n",
    "    \n",
    "    # Evaluate the model with the shuffled feature\n",
    "    score_with_permuted_feature = evaluate_model(oversampled_lrModel, shuffled_data, evaluator)\n",
    "    \n",
    "    # Calculate the drop in performance\n",
    "    importance = baseline_score - score_with_permuted_feature\n",
    "    feature_importances[feature] = importance\n",
    "\n",
    "# Sort the features by importance (i.e., the drop in F1 score)\n",
    "sorted_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Feature Importances (by drop in F1 score):\")\n",
    "for feature, importance in sorted_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a50f4-6e5f-40c1-93ec-aaa0900088a1",
   "metadata": {},
   "source": [
    "# Do Not Scale Data to Investigate Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af146fe0-c906-47dd-9036-5e81ec7171ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression model with intercept\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "lr = LogisticRegression(labelCol='Severity',\n",
    "                        featuresCol='features',\n",
    "                        maxIter=10, \n",
    "                        regParam=0.3, \n",
    "                        elasticNetParam=0.8,\n",
    "                        family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(train)\n",
    "print(f\"Detected number of classes: {lrModel.numClasses}\")\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ed86d-5f2a-4bde-8ab1-15d3bfb749de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you used StringIndexer for encoding the 'Severity' column\n",
    "indexer = StringIndexer(inputCol=\"Severity\", outputCol=\"SeverityIndex\")\n",
    "indexer_model = indexer.fit(train)\n",
    "indexer_model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff9f946-792b-4e84-b2d3-e628cf8e3aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# compute predictions. this will append column \"prediction\" to dataframe\n",
    "lrPred = lrModel.transform(test)\n",
    "lrPred.select(\"prediction\").distinct().show()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Severity', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(lrPred, {evaluator.metricName: \"accuracy\"})\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b8107-4eb2-4115-ace8-3ac62ed8ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = evaluator.evaluate(lrPred, {evaluator.metricName: 'weightedPrecision'})\n",
    "recall = evaluator.evaluate(lrPred, {evaluator.metricName: 'weightedRecall'})\n",
    "f1_score = evaluator.evaluate(lrPred, {evaluator.metricName: 'f1'})\n",
    "#recallByLabel = evaluator.evaluate(lrPred, {evaluator.metricName: 'recallByLabel'})\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1_score}')\n",
    "#print(f'Recall by Label: {recallByLabel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099f3b7-b209-4ec4-8f4b-95d4a9e21ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to indicate correct or incorrect predictions\n",
    "predictions = lrPred.withColumn(\n",
    "    'is_correct', F.expr(\"CASE WHEN Severity = prediction THEN 1 ELSE 0 END\")\n",
    ")\n",
    "\n",
    "# Calculate accuracy by class\n",
    "accuracy_by_class = predictions.groupBy('Severity').agg(\n",
    "    (F.sum('is_correct') / F.count('Severity')).alias('accuracy')\n",
    ")\n",
    "\n",
    "# Show per-class accuracy\n",
    "accuracy_by_class.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb77139-b326-41cf-a556-b05ef5eee30e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, data, evaluator):\n",
    "    predictions = model.transform(data)\n",
    "    return evaluator.evaluate(predictions)\n",
    "\n",
    "# Initialize the evaluator (using F1 score here)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Calculate baseline performance on test data\n",
    "baseline_score = evaluate_model(lrModel, test, evaluator)\n",
    "print(f\"Baseline F1 score: {baseline_score}\")\n",
    "\n",
    "# Assuming you know which features were used in the VectorAssembler, replace these with the actual feature names\n",
    "feature_names = feature_list  # Replace with actual feature names from your dataset\n",
    "\n",
    "# Initialize a dictionary to store feature importances\n",
    "feature_importances = {}\n",
    "\n",
    "# Loop through each feature and calculate permutation importance\n",
    "for feature in feature_names:\n",
    "    # Shuffle the feature column\n",
    "    shuffled_data = test.withColumn(feature, F.rand())  # Shuffle values in the column\n",
    "    \n",
    "    # Evaluate the model with the shuffled feature\n",
    "    score_with_permuted_feature = evaluate_model(lrModel, shuffled_data, evaluator)\n",
    "    \n",
    "    # Calculate the drop in performance\n",
    "    importance = baseline_score - score_with_permuted_feature\n",
    "    feature_importances[feature] = importance\n",
    "\n",
    "# Sort the features by importance (i.e., the drop in F1 score)\n",
    "sorted_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Feature Importances (by drop in F1 score):\")\n",
    "for feature, importance in sorted_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
