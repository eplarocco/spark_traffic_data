{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question:\n",
    "### What are the most influential variables on the severity of accidents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful Paper:\n",
    "    https://www.sciencedirect.com/science/article/pii/S2590198223000611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display Spark Output in scrollable format within jupyter notebook\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "import holidays\n",
    "from datetime import datetime, timezone\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/03 13:21:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Instantiate Spark Session\n",
    "spark = (SparkSession\n",
    "  .builder\n",
    "  .appName(\"US_Accidents\")\n",
    "  .getOrCreate())\n",
    "spark.sparkContext.setLogLevel(\"ERROR\") #supress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+\n",
      "|Severity|Temperature(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Speed(mph)|Precipitation(in)|Weekday|Rush Hour|Holiday|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate Indicator|Sex ratio (males per 100 females)|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|MedianIncome_MarginOfError|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+\n",
      "|       2|            21|         85|          30|             1|             10|                0|      1|        1|      0|   0|   1|(3,[0],[0.0])|                         0|                   0|                             97.6|              8.0|              4.0|               13.1|    104583.0|                    6161.0|        1.0|                   0|                   1|          0|\n",
      "|       2|            51|         29|          29|            10|              8|                0|      1|        0|      0|   0|   0|(3,[0],[0.0])|                         1|                   0|                             89.6|              7.7|              5.8|               12.7|    128378.0|                    7418.0|      0.982|                   0|                   0|          0|\n",
      "|       3|            55|         83|          30|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   1|                             94.6|              6.9|              5.4|               17.3|     52577.0|                    2897.0|     0.9968|                   0|                   0|          0|\n",
      "|       2|            52|         94|          30|            10|              9|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            106.8|              6.4|              8.2|               11.6|     48740.0|                    3484.0|        1.0|                   0|                   0|          0|\n",
      "|       2|            25|         96|          30|             0|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             95.9|              5.6|              6.8|               14.4|     62956.0|                    2229.0|     0.9887|                   0|                   0|          0|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in Dataset\n",
    "df = spark.read.parquet(\"final_dataset.parquet\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+\n",
      "|Severity|Temperature(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Speed(mph)|Precipitation(in)|Weekday|Rush Hour|Holiday|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate Indicator|Sex ratio (males per 100 females)|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+\n",
      "|       2|            21|         85|          30|             1|             10|                0|      1|        1|      0|   0|   1|(3,[0],[0.0])|                         0|                   0|                             97.6|              8.0|              4.0|               13.1|    104583.0|        1.0|                   0|                   1|          0|\n",
      "|       2|            51|         29|          29|            10|              8|                0|      1|        0|      0|   0|   0|(3,[0],[0.0])|                         1|                   0|                             89.6|              7.7|              5.8|               12.7|    128378.0|      0.982|                   0|                   0|          0|\n",
      "|       3|            55|         83|          30|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   1|                             94.6|              6.9|              5.4|               17.3|     52577.0|     0.9968|                   0|                   0|          0|\n",
      "|       2|            52|         94|          30|            10|              9|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            106.8|              6.4|              8.2|               11.6|     48740.0|        1.0|                   0|                   0|          0|\n",
      "|       2|            25|         96|          30|             0|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             95.9|              5.6|              6.8|               14.4|     62956.0|     0.9887|                   0|                   0|          0|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove MedianIncome_MarginOfError\n",
    "df = df.drop('MedianIncome_MarginOfError')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Rows count : 7026806\n",
      "DataFrame Columns count : 24\n"
     ]
    }
   ],
   "source": [
    "# Get row count\n",
    "rows = df.count()\n",
    "print(f\"DataFrame Rows count : {rows}\")\n",
    "\n",
    "# Get columns count\n",
    "cols = len(df.columns)\n",
    "print(f\"DataFrame Columns count : {cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------------------+\n",
      "|Severity|  count|           percent|\n",
      "+--------+-------+------------------+\n",
      "|       1|  65142|0.9270499285165977|\n",
      "|       3|1123799|15.993027272988611|\n",
      "|       4| 178821|2.5448404296347444|\n",
      "|       2|5659044| 80.53508236886005|\n",
      "+--------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Class Imbalance\n",
    "cts = df.groupBy(\"Severity\").count().withColumn('percent', (F.col('count') / rows)*100)\n",
    "cts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underperforming Tests Overview:\n",
    "\n",
    "## Tried Random split (80/20)\n",
    "- As predicted, model predicted severity = 2 for everything and they accuracy = the % of test samples with label = 2\n",
    "\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "## Undersampling (80/20) - undersampled each class by the smallest class for the training set - testing set everything else\n",
    "- This decreased the training set to about 3.5% of the original data set and the accuracy (~32% reflected that)\n",
    "- With undersampling, the performance might change with the sample taken\n",
    "\n",
    "sample = (cts.select(\"count\").rdd.min()[0])*0.8 #Undersample each class by 80% of the smallest class\n",
    "\n",
    "class1 = sample/(cts.select(\"count\").where(cts.Severity == '1').rdd.min()[0])\n",
    "\n",
    "class2 = sample/(cts.select(\"count\").where(cts.Severity == '2').rdd.min()[0])\n",
    "\n",
    "class3 = sample/(cts.select(\"count\").where(cts.Severity == '3').rdd.min()[0])\n",
    "\n",
    "class4 = sample/(cts.select(\"count\").where(cts.Severity == '4').rdd.min()[0])\n",
    "\n",
    "df.createOrReplaceTempView(\"data_view\") #Create a temporary view to use SQL\n",
    "\n",
    "fractions = {1: class1, 2: class2, 3: class3, 4: class4} #downsample each class to 80% of the smallest class\n",
    "\n",
    "train_data = df.sampleBy(\"Severity\", fractions, seed=42) #Use stratified sampling to maintain class distribution\n",
    "\n",
    "test_data = df.subtract(train_data)\n",
    "\n",
    "## Did not try full Oversampling\n",
    "- I'm always wary of oversampling amplyfying outliers especially with such high class imbalance and with regression trees that are already prone to overfitting\n",
    "## A combination of oversampling and undersampling may be a nice compramise\n",
    "- Did not check\n",
    "\n",
    "## Binary Classification (1|2 = 0, 3|4 = 1)\n",
    "- Best so far - model f1 score ~ 0.77 with base rf model - will obviously be better as half the options to guess from but still major improvement\n",
    "\n",
    "features = df.select([col for col in df.columns if col != \"Severity\" and col != \"Severity_Binary\"]).columns # Select all features except target variable\n",
    "\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features') # Vectorize Features\n",
    "\n",
    "model = RandomForestClassifier(featuresCol = 'features', labelCol = 'Severity_Binary') # Model\n",
    "  \n",
    "pipeline = Pipeline(stages=[assembler, model]) # Creating the pipeline \n",
    "\n",
    "fit_model = pipeline.fit(train_data) #train\n",
    "\n",
    "results = fit_model.transform(test_data) #predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+---------------+\n",
      "|Temperature(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Speed(mph)|Precipitation(in)|Weekday|Rush Hour|Holiday|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate Indicator|Sex ratio (males per 100 females)|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|Severity_Binary|\n",
      "+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+---------------+\n",
      "|            21|         85|          30|             1|             10|                0|      1|        1|      0|   0|   1|(3,[0],[0.0])|                         0|                   0|                             97.6|              8.0|              4.0|               13.1|    104583.0|        1.0|                   0|                   1|          0|              0|\n",
      "|            51|         29|          29|            10|              8|                0|      1|        0|      0|   0|   0|(3,[0],[0.0])|                         1|                   0|                             89.6|              7.7|              5.8|               12.7|    128378.0|      0.982|                   0|                   0|          0|              0|\n",
      "|            55|         83|          30|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   1|                             94.6|              6.9|              5.4|               17.3|     52577.0|     0.9968|                   0|                   0|          0|              1|\n",
      "|            52|         94|          30|            10|              9|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            106.8|              6.4|              8.2|               11.6|     48740.0|        1.0|                   0|                   0|          0|              0|\n",
      "|            25|         96|          30|             0|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             95.9|              5.6|              6.8|               14.4|     62956.0|     0.9887|                   0|                   0|          0|              0|\n",
      "+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification (1 or 2 vs 3 or 4)\n",
    "df = df.withColumn('Severity_Binary', when((col(\"Severity\")==1) | (col(\"Severity\")==2), 0).otherwise(1))\n",
    "df = df.drop('Severity')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+------------------+\n",
      "|Severity_Binary|  count|           percent|\n",
      "+---------------+-------+------------------+\n",
      "|              1|1302620|18.537867702623352|\n",
      "|              0|5724186| 81.46213229737664|\n",
      "+---------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Class Imbalance\n",
    "cts = df.groupBy(\"Severity_Binary\").count().withColumn('percent', (F.col('count') / rows)*100)\n",
    "cts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Undersample each class by 80% of the smallest class\n",
    "sample = (cts.select(\"count\").rdd.min()[0])*0.8\n",
    "\n",
    "class0 = sample/(cts.select(\"count\").where(cts.Severity_Binary == '0').rdd.min()[0])\n",
    "class1 = sample/(cts.select(\"count\").where(cts.Severity_Binary == '1').rdd.min()[0])\n",
    "\n",
    "# Split Data by Class - Downsampling\n",
    "\n",
    "# Create a temporary view to use SQL\n",
    "df.createOrReplaceTempView(\"data_view\")\n",
    "\n",
    "# Calculate fractions for each class\n",
    "#fractions = df.groupBy(\"Severity\").count().rdd.map(lambda row: (row[0], 0.8)).collectAsMap() #samples 80% of each class\n",
    "fractions = {0: class0, 1: class1} #downsample each class to 80% of the smallest class\n",
    "\n",
    "# Use stratified sampling to maintain class distribution\n",
    "train_data = df.sampleBy(\"Severity_Binary\", fractions, seed=42)\n",
    "test_data = df.subtract(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.67624266274037\n",
      "+---------------+-------+------------------+\n",
      "|Severity_Binary|  count|           percent|\n",
      "+---------------+-------+------------------+\n",
      "|              1|1041869|49.962739031272356|\n",
      "|              0|1043423| 50.03726096872764|\n",
      "+---------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Overall % Sampled from DF\n",
    "print(train_data.count()/df.count()*100)\n",
    "\n",
    "# Print % Sampled for each class within Train Data\n",
    "train_data.groupBy(\"Severity_Binary\").count().withColumn('percent', (F.col('count') / train_data.count())*100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.54452563511786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:>                                                         (0 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+-----------------+\n",
      "|Severity_Binary|  count|          percent|\n",
      "+---------------+-------+-----------------+\n",
      "|              1| 233625|6.095511876888011|\n",
      "|              0|3599113|93.90448812311199|\n",
      "+---------------+-------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print Overall % Sampled from DF\n",
    "print(test_data.count()/df.count()*100)\n",
    "\n",
    "# Print % Sampled for each class within Train Data\n",
    "test_data.groupBy(\"Severity_Binary\").count().withColumn('percent', (F.col('count') / test_data.count())*100).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/apps/software/standard/core/pyspark/3.4.1-py3.11/lib/python3.11/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 34\u001b[0m\n\u001b[1;32m     28\u001b[0m crossval \u001b[38;5;241m=\u001b[39m CrossValidator(estimator\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[1;32m     29\u001b[0m                           estimatorParamMaps\u001b[38;5;241m=\u001b[39mparamGrid,\n\u001b[1;32m     30\u001b[0m                           evaluator\u001b[38;5;241m=\u001b[39mMulticlassClassificationEvaluator(labelCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeverity_Binary\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictionCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     31\u001b[0m                           numFolds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m cvModel \u001b[38;5;241m=\u001b[39m \u001b[43mcrossval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m     37\u001b[0m predictions \u001b[38;5;241m=\u001b[39m cvModel\u001b[38;5;241m.\u001b[39mtransform(test_data)\n",
      "File \u001b[0;32m/apps/software/standard/core/pyspark/3.4.1-py3.11/lib/python3.11/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/apps/software/standard/core/pyspark/3.4.1-py3.11/lib/python3.11/site-packages/pyspark/ml/tuning.py:847\u001b[0m, in \u001b[0;36mCrossValidator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    841\u001b[0m train \u001b[38;5;241m=\u001b[39m datasets[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m    843\u001b[0m tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m    844\u001b[0m     inheritable_thread_target,\n\u001b[1;32m    845\u001b[0m     _parallelFitTasks(est, train, eva, validation, epm, collectSubModelsParam),\n\u001b[1;32m    846\u001b[0m )\n\u001b[0;32m--> 847\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, metric, subModel \u001b[38;5;129;01min\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mimap_unordered(\u001b[38;5;28;01mlambda\u001b[39;00m f: f(), tasks):\n\u001b[1;32m    848\u001b[0m     metrics_all[i][j] \u001b[38;5;241m=\u001b[39m metric\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m collectSubModelsParam:\n",
      "File \u001b[0;32m/apps/software/standard/core/pyspark/3.4.1-py3.11/lib/python3.11/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/apps/software/standard/core/pyspark/3.4.1-py3.11/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Select all features except target variable\n",
    "feature_list = []\n",
    "for col in df.columns:\n",
    "    if col == 'Severity_Binary':\n",
    "        continue\n",
    "    else:\n",
    "        feature_list.append(col)\n",
    "\n",
    "# Vectorize Features\n",
    "assembler = VectorAssembler(inputCols=feature_list, outputCol='features')\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"Severity_Binary\", featuresCol=\"features\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "# Define the parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [3, 6, 8]) \\\n",
    "    .addGrid(rf.maxDepth, [3, 4, 5]) \\\n",
    "    .build()\n",
    "\n",
    "# Create a CrossValidator\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"Severity_Binary\", predictionCol=\"prediction\"),\n",
    "                          numFolds=5)\n",
    "\n",
    "# Fit the model\n",
    "cvModel = crossval.fit(train_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = cvModel.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Severity_Binary\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(predictions)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "# Get the best model\n",
    "bestModel = cvModel.bestModel\n",
    "print(bestModel.stages[-1]._java_obj.paramMap()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 577:============================================>            (7 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2855213.  743900.]\n",
      " [ 115948.  117677.]]\n",
      "Weighted Precision: 0.9107245963203416\n",
      "Weighted Recall: 0.7756569846412669\n",
      "Weighted F1 Score: 0.829251596545379\n",
      "Accuracy: 0.7756569846412669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Further Metrics on Best Model\n",
    "pred = cvModel.bestModel.transform(test_data)\n",
    "\n",
    "#Evaluate (Confusion Matrix, Accuracy, Weighted Precision, Recall, and F1 Score)\n",
    "predictionAndLabels = pred.select(\"prediction\", \"Severity_Binary\")\n",
    "metrics = MulticlassMetrics(predictionAndLabels.rdd.map(lambda x: tuple(map(float, x))))\n",
    "\n",
    "# Get confusion matrix\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "\n",
    "# Get precision, recall, and F1-score for each class\n",
    "print(f'Weighted Precision: {metrics.weightedPrecision}') #would expect to be good when test sample has high majority 0 class\n",
    "print(f'Weighted Recall: {metrics.weightedRecall}')\n",
    "print(f'Weighted F1 Score: {metrics.weightedFMeasure()}') #would like to optimize this (balance of precision and recall)\n",
    "print(f'Accuracy: {metrics.accuracy}') #could be skewed with imbalanced test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ROC Curve - he asked for ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "Temperature(F): 0.0009213015483506297\n",
      "Humidity(%): 0.002540609439652656\n",
      "Pressure(in): 0.020450333607135187\n",
      "Visibility(mi): 0.0013161062441105088\n",
      "Wind_Speed(mph): 0.0940699616214557\n",
      "Precipitation(in): 0.0\n",
      "Weekday: 0.0005017290970311592\n",
      "Rush Hour: 0.0\n",
      "Holiday: 0.0\n",
      "Rain: 0.0023240584289040468\n",
      "Snow: 0.0\n",
      "SeasonVec: 0.0\n",
      "Astronomical_TwilightIndex: 0.0\n",
      "Interstate Indicator: 0.0\n",
      "Sex ratio (males per 100 females): 0.0\n",
      "Percent_Age_15-19: 0.7070260166982979\n",
      "Percent_Age_20-24: 0.0002243347183741944\n",
      "Percent_Age_65_over: 0.0\n",
      "MedianIncome: 0.003956996597709727\n",
      "Urban_Ratio: 0.0\n",
      "Traffic_Interference: 0.01904514582410056\n",
      "Traffic_Intersection: 0.0169767010785899\n",
      "Destination: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Feature Importances\n",
    "bestModel = cvModel.bestModel.stages[-1]  # Assuming the last stage in the pipeline is the model\n",
    "\n",
    "featureImportances = bestModel.featureImportances\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(test_data.columns[:-1], featureImportances):\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(25, {0: 0.0009, 1: 0.0025, 2: 0.0205, 3: 0.0013, 4: 0.0941, 6: 0.0005, 9: 0.0023, 15: 0.707, 16: 0.0002, 18: 0.004, 20: 0.019, 21: 0.017, 23: 0.1054, 24: 0.0253})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.featureImportances #why are there 35?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
