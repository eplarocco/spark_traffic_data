{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question:\n",
    "### What are the most influential variables on the severity of accidents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful Paper:\n",
    "    https://www.sciencedirect.com/science/article/pii/S2590198223000611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display Spark Output in scrollable format within jupyter notebook\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Supress Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "import holidays\n",
    "from datetime import datetime, timezone\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/01 14:46:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Instantiate Spark Session\n",
    "spark = (SparkSession\n",
    "  .builder\n",
    "  .appName(\"US_Accidents\")\n",
    "  .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+\n",
      "|Severity|Temperature(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Speed(mph)|Precipitation(in)|Weekday|Rush Hour|Holiday|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate Indicator|Sex ratio (males per 100 females)|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|MedianIncome_MarginOfError|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+\n",
      "|       2|            21|         85|          30|             1|             10|                0|      1|        1|      0|   0|   1|(3,[0],[0.0])|                         0|                   0|                             97.6|              8.0|              4.0|               13.1|    104583.0|                    6161.0|        1.0|                   0|                   1|          0|\n",
      "|       2|            51|         29|          29|            10|              8|                0|      1|        0|      0|   0|   0|(3,[0],[0.0])|                         1|                   0|                             89.6|              7.7|              5.8|               12.7|    128378.0|                    7418.0|      0.982|                   0|                   0|          0|\n",
      "|       3|            55|         83|          30|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   1|                             94.6|              6.9|              5.4|               17.3|     52577.0|                    2897.0|     0.9968|                   0|                   0|          0|\n",
      "|       2|            52|         94|          30|            10|              9|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            106.8|              6.4|              8.2|               11.6|     48740.0|                    3484.0|        1.0|                   0|                   0|          0|\n",
      "|       2|            25|         96|          30|             0|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             95.9|              5.6|              6.8|               14.4|     62956.0|                    2229.0|     0.9887|                   0|                   0|          0|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+--------------------------+-----------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in Dataset\n",
    "df = spark.read.parquet(\"final_dataset.parquet\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+\n",
      "|Severity|Temperature(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Speed(mph)|Precipitation(in)|Weekday|Rush Hour|Holiday|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate Indicator|Sex ratio (males per 100 females)|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+\n",
      "|       2|            21|         85|          30|             1|             10|                0|      1|        1|      0|   0|   1|(3,[0],[0.0])|                         0|                   0|                             97.6|              8.0|              4.0|               13.1|    104583.0|        1.0|                   0|                   1|          0|\n",
      "|       2|            51|         29|          29|            10|              8|                0|      1|        0|      0|   0|   0|(3,[0],[0.0])|                         1|                   0|                             89.6|              7.7|              5.8|               12.7|    128378.0|      0.982|                   0|                   0|          0|\n",
      "|       3|            55|         83|          30|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   1|                             94.6|              6.9|              5.4|               17.3|     52577.0|     0.9968|                   0|                   0|          0|\n",
      "|       2|            52|         94|          30|            10|              9|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            106.8|              6.4|              8.2|               11.6|     48740.0|        1.0|                   0|                   0|          0|\n",
      "|       2|            25|         96|          30|             0|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             95.9|              5.6|              6.8|               14.4|     62956.0|     0.9887|                   0|                   0|          0|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove MedianIncome_MarginOfError\n",
    "df = df.drop('MedianIncome_MarginOfError')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Rows count : 7026806\n",
      "DataFrame Columns count : 24\n"
     ]
    }
   ],
   "source": [
    "# Get row count\n",
    "rows = df.count()\n",
    "print(f\"DataFrame Rows count : {rows}\")\n",
    "\n",
    "# Get columns count\n",
    "cols = len(df.columns)\n",
    "print(f\"DataFrame Columns count : {cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------------------+\n",
      "|Severity|  count|           percent|\n",
      "+--------+-------+------------------+\n",
      "|       1|  65142|0.9270499285165977|\n",
      "|       3|1123799|15.993027272988611|\n",
      "|       4| 178821|2.5448404296347444|\n",
      "|       2|5659044| 80.53508236886005|\n",
      "+--------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Class Imbalance\n",
    "cts = df.groupBy(\"Severity\").count().withColumn('percent', (F.col('count') / rows)*100)\n",
    "cts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "#Model just guessed severity = 2 for everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Undersample each class by 80% of the smallest class\n",
    "sample = (cts.select(\"count\").rdd.min()[0])*0.8\n",
    "\n",
    "class1 = sample/(cts.select(\"count\").where(cts.Severity == '1').rdd.min()[0])\n",
    "class2 = sample/(cts.select(\"count\").where(cts.Severity == '2').rdd.min()[0])\n",
    "class3 = sample/(cts.select(\"count\").where(cts.Severity == '3').rdd.min()[0])\n",
    "class4 = sample/(cts.select(\"count\").where(cts.Severity == '4').rdd.min()[0])\n",
    "\n",
    "# Split Data by Class - Downsampling\n",
    "\n",
    "# Create a temporary view to use SQL\n",
    "df.createOrReplaceTempView(\"data_view\")\n",
    "\n",
    "# Calculate fractions for each class\n",
    "#fractions = df.groupBy(\"Severity\").count().rdd.map(lambda row: (row[0], 0.8)).collectAsMap() #samples 80% of each class\n",
    "fractions = {1: class1, 2: class2, 3: class3, 4: class4} #downsample each class to 80% of the smallest class\n",
    "\n",
    "# Use stratified sampling to maintain class distribution\n",
    "train_data = df.sampleBy(\"Severity\", fractions, seed=42)\n",
    "test_data = df.subtract(train_data)\n",
    "\n",
    "#Model performed ~32% accuracy - great precision though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+---------------+\n",
      "|Severity|Temperature(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Speed(mph)|Precipitation(in)|Weekday|Rush Hour|Holiday|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate Indicator|Sex ratio (males per 100 females)|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|Severity_Binary|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+---------------+\n",
      "|       2|            21|         85|          30|             1|             10|                0|      1|        1|      0|   0|   1|(3,[0],[0.0])|                         0|                   0|                             97.6|              8.0|              4.0|               13.1|    104583.0|        1.0|                   0|                   1|          0|              0|\n",
      "|       2|            51|         29|          29|            10|              8|                0|      1|        0|      0|   0|   0|(3,[0],[0.0])|                         1|                   0|                             89.6|              7.7|              5.8|               12.7|    128378.0|      0.982|                   0|                   0|          0|              0|\n",
      "|       3|            55|         83|          30|            10|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   1|                             94.6|              6.9|              5.4|               17.3|     52577.0|     0.9968|                   0|                   0|          0|              1|\n",
      "|       2|            52|         94|          30|            10|              9|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                            106.8|              6.4|              8.2|               11.6|     48740.0|        1.0|                   0|                   0|          0|              0|\n",
      "|       2|            25|         96|          30|             0|              0|                0|      1|        1|      0|   0|   0|(3,[0],[0.0])|                         0|                   0|                             95.9|              5.6|              6.8|               14.4|     62956.0|     0.9887|                   0|                   0|          0|              0|\n",
      "+--------+--------------+-----------+------------+--------------+---------------+-----------------+-------+---------+-------+----+----+-------------+--------------------------+--------------------+---------------------------------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification (1 or 2 vs 3 or 4)\n",
    "df = df.withColumn('Severity_Binary', when((col(\"Severity\")==1) | (col(\"Severity\")==2), 0).otherwise(1))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+------------------+\n",
      "|Severity_Binary|  count|           percent|\n",
      "+---------------+-------+------------------+\n",
      "|              1|1302620|18.537867702623352|\n",
      "|              0|5724186| 81.46213229737664|\n",
      "+---------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Class Imbalance\n",
    "cts = df.groupBy(\"Severity_Binary\").count().withColumn('percent', (F.col('count') / rows)*100)\n",
    "cts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Undersample each class by 80% of the smallest class\n",
    "sample = (cts.select(\"count\").rdd.min()[0])*0.8\n",
    "\n",
    "class0 = sample/(cts.select(\"count\").where(cts.Severity_Binary == '0').rdd.min()[0])\n",
    "class1 = sample/(cts.select(\"count\").where(cts.Severity_Binary == '1').rdd.min()[0])\n",
    "\n",
    "# Split Data by Class - Downsampling\n",
    "\n",
    "# Create a temporary view to use SQL\n",
    "df.createOrReplaceTempView(\"data_view\")\n",
    "\n",
    "# Calculate fractions for each class\n",
    "#fractions = df.groupBy(\"Severity\").count().rdd.map(lambda row: (row[0], 0.8)).collectAsMap() #samples 80% of each class\n",
    "fractions = {0: class0, 1: class1} #downsample each class to 80% of the smallest class\n",
    "\n",
    "# Use stratified sampling to maintain class distribution\n",
    "train_data = df.sampleBy(\"Severity_Binary\", fractions, seed=42)\n",
    "test_data = df.subtract(train_data)\n",
    "\n",
    "#Model performed ~77% accuracy with base rf model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/01 15:37:10 WARN MemoryStore: Not enough space to cache rdd_814_0 in memory! (computed 11.7 MiB so far)\n",
      "24/11/01 15:37:10 WARN BlockManager: Persisting block rdd_814_0 to disk instead.\n",
      "24/11/01 15:37:10 WARN MemoryStore: Not enough space to cache rdd_814_4 in memory! (computed 18.0 MiB so far)\n",
      "24/11/01 15:37:10 WARN BlockManager: Persisting block rdd_814_4 to disk instead.\n",
      "24/11/01 15:37:11 WARN MemoryStore: Not enough space to cache rdd_814_5 in memory! (computed 27.1 MiB so far)\n",
      "24/11/01 15:37:11 WARN BlockManager: Persisting block rdd_814_5 to disk instead.\n",
      "24/11/01 15:37:11 WARN MemoryStore: Not enough space to cache rdd_814_3 in memory! (computed 27.1 MiB so far)\n",
      "24/11/01 15:37:11 WARN BlockManager: Persisting block rdd_814_3 to disk instead.\n",
      "24/11/01 15:37:11 WARN MemoryStore: Not enough space to cache rdd_814_2 in memory! (computed 18.0 MiB so far)\n",
      "24/11/01 15:37:11 WARN BlockManager: Persisting block rdd_814_2 to disk instead.\n",
      "24/11/01 15:37:11 WARN MemoryStore: Not enough space to cache rdd_814_6 in memory! (computed 61.4 MiB so far)\n",
      "24/11/01 15:37:11 WARN BlockManager: Persisting block rdd_814_6 to disk instead.\n",
      "24/11/01 15:37:14 WARN MemoryStore: Not enough space to cache rdd_814_1 in memory! (computed 140.7 MiB so far)\n",
      "24/11/01 15:37:14 WARN BlockManager: Persisting block rdd_814_1 to disk instead.\n",
      "24/11/01 15:37:15 WARN MemoryStore: Not enough space to cache rdd_814_6 in memory! (computed 27.1 MiB so far)\n",
      "24/11/01 15:37:16 WARN MemoryStore: Not enough space to cache rdd_814_1 in memory! (computed 18.0 MiB so far)\n",
      "24/11/01 15:37:16 WARN MemoryStore: Not enough space to cache rdd_814_2 in memory! (computed 5.1 MiB so far)\n",
      "24/11/01 15:37:16 WARN MemoryStore: Not enough space to cache rdd_814_4 in memory! (computed 40.6 MiB so far)\n",
      "24/11/01 15:37:16 WARN MemoryStore: Not enough space to cache rdd_814_3 in memory! (computed 93.8 MiB so far)\n",
      "24/11/01 15:37:17 WARN MemoryStore: Not enough space to cache rdd_814_0 in memory! (computed 93.8 MiB so far)\n",
      "24/11/01 15:37:18 WARN MemoryStore: Not enough space to cache rdd_814_2 in memory! (computed 18.0 MiB so far)\n",
      "24/11/01 15:37:18 WARN MemoryStore: Not enough space to cache rdd_814_0 in memory! (computed 18.0 MiB so far)\n",
      "24/11/01 15:37:18 WARN MemoryStore: Not enough space to cache rdd_814_1 in memory! (computed 18.0 MiB so far)\n",
      "24/11/01 15:37:18 WARN MemoryStore: Not enough space to cache rdd_814_6 in memory! (computed 18.0 MiB so far)\n",
      "24/11/01 15:37:18 WARN MemoryStore: Not enough space to cache rdd_814_4 in memory! (computed 61.4 MiB so far)\n",
      "24/11/01 15:37:18 WARN MemoryStore: Not enough space to cache rdd_814_3 in memory! (computed 61.4 MiB so far)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Select all features except target variable\n",
    "features = df.select([col for col in df.columns if col != \"Severity\" and col != \"Severity_Binary\"]).columns\n",
    "\n",
    "# Vectorize Features\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "\n",
    "# Model\n",
    "model = RandomForestClassifier(featuresCol = 'features', labelCol = 'Severity_Binary', numTrees=3, maxDepth=2)\n",
    "  \n",
    "# Creating the pipeline \n",
    "pipeline = Pipeline(stages=[assembler, model])\n",
    "\n",
    "fit_model = pipeline.fit(train_data)\n",
    "results = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 256:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1145667.       0.]\n",
      " [ 260410.       0.]]\n",
      "Weighted Precision: 0.6638937787536361\n",
      "Weighted Recall: 0.8147967714428157\n",
      "Weighted F1 Score: 0.7316453161042615\n",
      "Accuracy: 0.8147967714428157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Metrics (Confusion Matrix, Accuracy, Weighted Precision, Recall, and F1 Score)\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "predictionAndLabels = results.select(\"prediction\", \"Severity_Binary\")\n",
    "metrics = MulticlassMetrics(predictionAndLabels.rdd.map(lambda x: tuple(map(float, x))))\n",
    "\n",
    "# Get confusion matrix\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "\n",
    "# Get precision, recall, and F1-score for each class\n",
    "print(f'Weighted Precision: {metrics.weightedPrecision}')\n",
    "print(f'Weighted Recall: {metrics.weightedRecall}')\n",
    "print(f'Weighted F1 Score: {metrics.weightedFMeasure()}')\n",
    "print(f'Accuracy: {metrics.accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.970026495679545\n",
      "+--------+-----+------------------+\n",
      "|Severity|count|           percent|\n",
      "+--------+-----+------------------+\n",
      "|       1|52012|24.922136292633372|\n",
      "|       3|51869| 24.85361623015074|\n",
      "|       4|52207|25.015572741473324|\n",
      "|       2|52610| 25.20867473574256|\n",
      "+--------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Overall % Sampled from DF\n",
    "print(train_data.count()/df.count()*100)\n",
    "\n",
    "# Print % Sampled for each class within Train Data\n",
    "train_data.groupBy(\"Severity\").count().withColumn('percent', (F.col('count') / train_data.count())*100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.87516661197137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/01 14:26:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 200:======================================>                 (9 + 4) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------------------+\n",
      "|Severity|  count|           percent|\n",
      "+--------+-------+------------------+\n",
      "|       1|  10966|0.1953792782868341|\n",
      "|       3|1029576|18.343773100624247|\n",
      "|       4|  95412| 1.699938692312914|\n",
      "|       2|4476719|   79.760908928776|\n",
      "+--------+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print Overall % Sampled from DF\n",
    "print(test_data.count()/df.count()*100)\n",
    "\n",
    "# Print % Sampled for each class within Train Data\n",
    "test_data.groupBy(\"Severity\").count().withColumn('percent', (F.col('count') / test_data.count())*100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Pipeline\n",
    "from pyspark.ml import Pipeline \n",
    "  \n",
    "model = ########################### Model Here ###########################\n",
    "  \n",
    "# Creating the pipeline \n",
    "pipe = Pipeline(stages=[model]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fitting the model on training data \n",
    "fit_model = pipe.fit(scaledData_train) \n",
    "  \n",
    "# Storing the results on test data \n",
    "results = fit_model.transform(scaledData_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ROC Curve - he asked for ROC curve but usually only for binary classification - could do 4 one-vs-all roc curves?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
