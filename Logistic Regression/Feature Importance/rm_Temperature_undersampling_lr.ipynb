{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf6ccc1-6317-482a-ac30-72c6eab49a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "import holidays\n",
    "from datetime import datetime, timezone\n",
    "from pyspark.ml.classification import RandomForestClassifier, BinaryLogisticRegressionSummary\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\n",
    "from pyspark.ml.pipeline import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0709727-12cd-4322-b2e8-5ceca8b3b502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/14 11:27:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/14 11:27:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Spark Session\n",
    "spark = (SparkSession\n",
    "  .builder\n",
    "  .appName(\"US_Accidents\")\n",
    "  .getOrCreate())\n",
    "spark.sparkContext.setLogLevel(\"ERROR\") #supress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a537b4-0516-49a4-a9d3-9957ecf6972b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read in Data\n",
    "df = spark.read.parquet(\"final_dataset_revised.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6be913b-8a20-494f-af35-4cc44879acb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Use StringIndexer for encoding the 'Severity' column\n",
    "indexer = StringIndexer(inputCol=\"Severity\", outputCol=\"SeverityIndex\")\n",
    "df = indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb96fd0f-7581-467f-a0c3-948425bd9ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of features\n",
    "feature_list = []\n",
    "for col in df.columns:\n",
    "    if col == 'Severity':\n",
    "        continue\n",
    "    elif col == 'SeverityIndex':\n",
    "        continue\n",
    "    elif col == 'Temperature':\n",
    "        continue\n",
    "    else:\n",
    "        feature_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8117f0e8-de44-4430-aa72-8899adcaeae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "splits = df.randomSplit([0.8, 0.2], 314)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827fa4c6-689b-4ea8-9b72-5fdbf8d7ecb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------+--------+----------+----------+-------------+-------+---------+----+----+-------------+--------------------------+--------------------+---------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+-------------+\n",
      "|Severity|Temperature|Humidity|Pressure|Visibility|Wind_Speed|Precipitation|Weekday|Rush_Hour|Rain|Snow|    SeasonVec|Astronomical_TwilightIndex|Interstate_Indicator|Sex_ratio|Percent_Age_15-19|Percent_Age_20-24|Percent_Age_65_over|MedianIncome|Urban_Ratio|Traffic_Interference|Traffic_Intersection|Destination|SeverityIndex|\n",
      "+--------+-----------+--------+--------+----------+----------+-------------+-------+---------+----+----+-------------+--------------------------+--------------------+---------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+-------------+\n",
      "|       2|        -15|      75|      29|        10|         7|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|    101.2|              5.1|              4.9|               15.4|     66852.0|        1.0|                   0|                   0|          0|          0.0|\n",
      "|       2|          5|      61|      30|        10|         9|            0|      1|        0|   0|   0|(3,[0],[1.0])|                         0|                   0|    100.5|             12.2|             10.7|               15.6|     81953.0|     0.9663|                   0|                   0|          0|          0.0|\n",
      "|       2|         10|      85|      29|         1|         9|            0|      1|        1|   0|   1|(3,[0],[1.0])|                         0|                   0|    113.1|              6.3|              5.1|               20.1|     58860.0|        0.0|                   0|                   0|          0|          0.0|\n",
      "|       2|         13|      91|      30|        10|         0|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|     89.3|              7.3|              8.4|               22.7|     76586.0|        1.0|                   0|                   1|          0|          0.0|\n",
      "|       2|         14|      52|      30|        10|         5|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|    100.2|              1.5|              7.7|                3.2|    120000.0|        1.0|                   0|                   1|          1|          0.0|\n",
      "|       2|         16|      49|      29|        10|         6|            0|      1|        0|   0|   0|(3,[0],[1.0])|                         0|                   0|    102.2|              5.9|              7.0|               13.3|     53973.0|     0.9908|                   0|                   1|          0|          0.0|\n",
      "|       2|         16|      49|      30|        10|         7|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   1|     89.1|              5.6|              4.5|               17.8|     97635.0|        1.0|                   0|                   0|          0|          0.0|\n",
      "|       2|         16|      52|      30|        10|        17|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|    100.4|              6.0|              4.6|               19.7|     50246.0|        0.0|                   0|                   0|          0|          0.0|\n",
      "|       2|         16|      86|      30|        10|         0|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|     98.7|              8.1|              5.1|               16.3|    136667.0|     0.2891|                   0|                   0|          0|          0.0|\n",
      "|       2|         17|      81|      24|        10|         3|            0|      0|        1|   0|   0|(3,[0],[1.0])|                         0|                   1|     98.5|              3.5|              6.0|               21.6|     55813.0|        0.0|                   0|                   0|          0|          0.0|\n",
      "|       2|         18|      53|      30|        15|        15|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   1|     93.9|              6.1|              5.9|               18.8|     49036.0|       0.68|                   0|                   0|          0|          0.0|\n",
      "|       2|         18|      54|      29|         9|        10|            0|      1|        0|   0|   0|(3,[0],[1.0])|                         0|                   0|     93.8|              4.4|              4.3|               18.1|     68426.0|        1.0|                   0|                   1|          0|          0.0|\n",
      "|       2|         19|      54|      30|        10|         0|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|     92.6|              8.5|              7.0|               18.6|     96373.0|     0.8734|                   0|                   1|          1|          0.0|\n",
      "|       2|         19|      85|      29|         1|         6|            0|      1|        1|   0|   1|(3,[0],[1.0])|                         0|                   0|     93.6|              6.7|              6.5|               16.2|     33747.0|     0.8132|                   0|                   1|          0|          0.0|\n",
      "|       2|         19|      86|      30|        10|         0|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|     89.6|              7.4|              7.5|               11.3|    111711.0|        1.0|                   0|                   0|          0|          0.0|\n",
      "|       2|         21|      33|      30|        10|         9|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   0|     98.0|              8.4|              6.1|               12.8|     86570.0|        1.0|                   0|                   0|          0|          0.0|\n",
      "|       2|         21|      74|      29|        10|         6|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   1|     94.2|              5.9|              4.6|               21.7|     70813.0|     0.8739|                   0|                   0|          0|          0.0|\n",
      "|       2|         21|      88|      29|         1|         7|            0|      1|        0|   0|   1|(3,[0],[1.0])|                         1|                   0|     89.8|              8.0|              8.5|               15.6|     25949.0|     0.9915|                   0|                   0|          0|          0.0|\n",
      "|       2|         21|      88|      29|         1|         7|            0|      1|        0|   0|   1|(3,[0],[1.0])|                         1|                   0|     93.5|              7.3|              8.7|               14.5|     31685.0|     0.9808|                   0|                   0|          0|          0.0|\n",
      "|       2|         21|     100|      28|        10|         0|            0|      1|        1|   0|   0|(3,[0],[1.0])|                         0|                   1|     99.4|              4.6|              4.6|               15.4|     60039.0|     0.7907|                   0|                   0|          0|          0.0|\n",
      "+--------+-----------+--------+--------+----------+----------+-------------+-------+---------+----+----+-------------+--------------------------+--------------------+---------+-----------------+-----------------+-------------------+------------+-----------+--------------------+--------------------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|SeverityIndex|count|\n",
      "+-------------+-----+\n",
      "|          0.0|52213|\n",
      "|          1.0|52002|\n",
      "|          3.0|52136|\n",
      "|          2.0|51932|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Undersampling\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Step 1: Group by 'Severity' and count occurrences\n",
    "class_counts = train.groupBy(\"SeverityIndex\").count()\n",
    "\n",
    "# Step 2: Use PySpark's min() function to find the minimum count\n",
    "min_class_size = class_counts.agg(F.min('count')).collect()[0][0]\n",
    "\n",
    "undersampled_train_list = []\n",
    "\n",
    "for row in class_counts.collect():\n",
    "    class_label = row['SeverityIndex']\n",
    "    class_size = row['count']\n",
    "\n",
    "    if class_size > min_class_size:\n",
    "        # Sample the data for this class to the size of the minimum class\n",
    "        class_data = train.filter(F.col(\"SeverityIndex\") == class_label)\n",
    "        class_data_undersampled = class_data.sample(withReplacement=False, fraction=min_class_size / class_size)\n",
    "    else:\n",
    "        # For classes that are already at the minimum size, keep all samples\n",
    "        class_data_undersampled = train.filter(F.col(\"SeverityIndex\") == class_label)\n",
    "\n",
    "    undersampled_train_list.append(class_data_undersampled)\n",
    "\n",
    "# Combine all the undersampled DataFrames\n",
    "undersampled_train = undersampled_train_list[0]  # start with the first one\n",
    "for df in undersampled_train_list[1:]:\n",
    "    undersampled_train = undersampled_train.union(df)\n",
    "\n",
    "# Show the result\n",
    "undersampled_train.show()\n",
    "\n",
    "# Step 4: Group by 'Severity' and count the occurrences in the undersampled DataFrame\n",
    "undersampled_class_counts = undersampled_train.groupBy(\"SeverityIndex\").count()\n",
    "\n",
    "# Show the result\n",
    "undersampled_class_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d79048b-55fa-4cac-9ce6-00d115340220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble data for logistic regression model\n",
    "assembler = VectorAssembler(inputCols=feature_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "undersampled_train = assembler.transform(undersampled_train)\n",
    "test = assembler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5e00b4-277f-4dff-b480-5bcb8acdc8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Standardize the predictors\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(undersampled_train)\n",
    "scaledTrainData = scalerModel.transform(undersampled_train)\n",
    "scaledTestData = scalerModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54cb60dc-688a-45e9-b2fe-bf00d4ec87f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected number of classes: 4\n",
      "Coefficients: DenseMatrix([[-4.94264049e-02,  7.70802107e-03, -4.52243021e-02,\n",
      "              -1.01507294e-02,  3.42922395e-03, -4.44190730e-02,\n",
      "              -4.68445935e-02, -1.14712967e-02,  3.60967127e-02,\n",
      "               5.12549981e-01,  3.23782277e-01,  1.28223238e-02,\n",
      "              -6.79420213e-03, -9.44357391e-02,  3.07689521e-03,\n",
      "              -1.60019928e-02,  1.67674980e-02,  2.59327142e-02,\n",
      "               1.08304692e-02,  3.75036902e-02, -3.60395426e-03,\n",
      "              -2.86777026e-02,  6.02327799e-02],\n",
      "             [-2.68639475e-02,  5.84953055e-03, -3.22607546e-02,\n",
      "               1.12695194e-01,  4.59644473e-03, -7.56010363e-02,\n",
      "              -1.64771164e-02,  2.96394018e-02,  2.00079077e-02,\n",
      "               2.97826113e-01,  1.86212870e-01, -7.12008809e-02,\n",
      "              -1.15217944e-01,  4.48703587e-01, -6.32723219e-03,\n",
      "              -7.87891767e-02, -5.08319353e-03, -1.73570735e-01,\n",
      "               1.79916823e-02,  2.50898793e-01,  4.13440913e-03,\n",
      "              -2.70687906e-01, -9.19252583e-02],\n",
      "             [ 3.67293163e-02,  2.79594746e-02,  4.03414840e-02,\n",
      "               6.50211542e-02, -8.74442829e-03, -1.41644749e-01,\n",
      "              -1.64384145e-01,  1.54422854e-02,  7.57813264e-02,\n",
      "               3.65096891e-01,  2.14155899e-01,  2.68820975e-02,\n",
      "               1.81456791e-01, -3.44777012e-03,  4.48452554e-03,\n",
      "               4.79396398e-02, -1.88176012e-02,  9.65605799e-02,\n",
      "               7.40109546e-04, -4.35876906e-01, -6.86845307e-03,\n",
      "              -2.40135443e-02, -8.27333966e-03],\n",
      "             [ 3.95610361e-02, -4.15170262e-02,  3.71435727e-02,\n",
      "              -1.67565619e-01,  7.18759607e-04,  2.61664858e-01,\n",
      "               2.27705855e-01, -3.36103904e-02, -1.31885947e-01,\n",
      "              -1.17547298e+00, -7.24151046e-01,  3.14964596e-02,\n",
      "              -5.94446457e-02, -3.50820078e-01, -1.23418855e-03,\n",
      "               4.68515298e-02,  7.13329680e-03,  5.10774406e-02,\n",
      "              -2.95622610e-02,  1.47474423e-01,  6.33799819e-03,\n",
      "               3.23379152e-01,  3.99658181e-02]])\n",
      "Intercept: [-0.004966201694913743,-0.09459321589651662,0.016053754556109846,0.08350566303532052]\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression model with intercept\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "lr = LogisticRegression(labelCol='SeverityIndex',\n",
    "                        featuresCol='scaledFeatures',\n",
    "                        #maxIter=10, \n",
    "                        #regParam=0.3, \n",
    "                        #elasticNetParam=0.8,\n",
    "                        family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(scaledTrainData)\n",
    "print(f\"Detected number of classes: {lrModel.numClasses}\")\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9646a1f-7a43-4a74-8e3d-e64dd3a11062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "|       1.0|\n",
      "|       3.0|\n",
      "|       2.0|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 251:========================================>              (17 + 6) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.384011194454562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# compute predictions. this will append column \"prediction\" to dataframe\n",
    "lrPred = lrModel.transform(scaledTestData)\n",
    "lrPred.select(\"prediction\").distinct().show()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='SeverityIndex', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(lrPred, {evaluator.metricName: \"accuracy\"})\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3e81050-0bf6-4e42-b0c8-f7ebe09b0971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 257:================>                                      (7 + 16) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7662978111097712\n",
      "Recall: 0.38401119445456205\n",
      "F1 Score: 0.4765187264647403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "precision = evaluator.evaluate(lrPred, {evaluator.metricName: 'weightedPrecision'})\n",
    "recall = evaluator.evaluate(lrPred, {evaluator.metricName: 'weightedRecall'})\n",
    "f1_score = evaluator.evaluate(lrPred, {evaluator.metricName: 'f1'})\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05e473cd-b658-4a72-ba3a-f5d2752719eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 259:=============================================>         (19 + 4) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|SeverityIndex|          accuracy|\n",
      "+-------------+------------------+\n",
      "|          0.0|0.3591001242560984|\n",
      "|          1.0|0.4803294904608342|\n",
      "|          3.0|0.7867138243887437|\n",
      "|          2.0|0.4186241845619733|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Add a column to indicate correct or incorrect predictions\n",
    "predictions = lrPred.withColumn(\n",
    "    'is_correct', F.expr(\"CASE WHEN SeverityIndex = prediction THEN 1 ELSE 0 END\")\n",
    ")\n",
    "\n",
    "# Calculate accuracy by class\n",
    "accuracy_by_class = predictions.groupBy('SeverityIndex').agg(\n",
    "    (F.sum('is_correct') / F.count('SeverityIndex')).alias('accuracy')\n",
    ")\n",
    "\n",
    "# Show per-class accuracy\n",
    "accuracy_by_class.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
